{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clasificación con MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bruno César Gonzalez\n",
    "150370"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta sección vamos a demostrar el poder de las redes neuronales conPyTorch. Vamos a usar el conjunto de datosMNIST1\n",
    "1. Instaletorchytorchvisionen su computadora.\n",
    "2. Cree una carpeta llamadadatosen su carpeta de trabajomkdir ./datos.\n",
    "3. Lea acerca de la capa lineal de PyTorchhttps://pytorch.org/docs/stable/nn.html#torch.nn.Linear.\n",
    "4. Cree un archivomodelos.pye implemente el siguiente código que implementaregresión logística multinomial.Rellene las líneas[COMENTARIO]para explicar que hace cada segmento de código."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "# ==================\n",
    "# Regresion logistica multinomial\n",
    "# ==================\n",
    "class RegresionMultinomial(nn.Module):\n",
    "  def __init__(self, input_size, num_classes):\n",
    "    super(RegresionMultinomial, self).__init__()\n",
    "    self.linear = nn.Linear(input_size, num_classes)\n",
    "    \n",
    "  def forward(self, x):\n",
    "    out = self.linear(x)\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Puede probar el modelo RegresionMultinomialcon el siguiente código. Rellene las líneas de [COMENTARIO]para explicar las diferentes secciones del código."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoca: 1/5, Paso: 100/600, Perdida: 2.16616\n",
      "Epoca: 1/5, Paso: 200/600, Perdida: 2.07468\n",
      "Epoca: 1/5, Paso: 300/600, Perdida: 1.99461\n",
      "Epoca: 1/5, Paso: 400/600, Perdida: 1.92590\n",
      "Epoca: 1/5, Paso: 500/600, Perdida: 1.87350\n",
      "Epoca: 1/5, Paso: 600/600, Perdida: 1.74184\n",
      "Epoca: 2/5, Paso: 100/600, Perdida: 1.71520\n",
      "Epoca: 2/5, Paso: 200/600, Perdida: 1.65066\n",
      "Epoca: 2/5, Paso: 300/600, Perdida: 1.58322\n",
      "Epoca: 2/5, Paso: 400/600, Perdida: 1.59248\n",
      "Epoca: 2/5, Paso: 500/600, Perdida: 1.43114\n",
      "Epoca: 2/5, Paso: 600/600, Perdida: 1.47023\n",
      "Epoca: 3/5, Paso: 100/600, Perdida: 1.36498\n",
      "Epoca: 3/5, Paso: 200/600, Perdida: 1.33142\n",
      "Epoca: 3/5, Paso: 300/600, Perdida: 1.39326\n",
      "Epoca: 3/5, Paso: 400/600, Perdida: 1.43480\n",
      "Epoca: 3/5, Paso: 500/600, Perdida: 1.40112\n",
      "Epoca: 3/5, Paso: 600/600, Perdida: 1.19735\n",
      "Epoca: 4/5, Paso: 100/600, Perdida: 1.20553\n",
      "Epoca: 4/5, Paso: 200/600, Perdida: 1.20173\n",
      "Epoca: 4/5, Paso: 300/600, Perdida: 1.18362\n",
      "Epoca: 4/5, Paso: 400/600, Perdida: 1.15534\n",
      "Epoca: 4/5, Paso: 500/600, Perdida: 1.18604\n",
      "Epoca: 4/5, Paso: 600/600, Perdida: 1.11730\n",
      "Epoca: 5/5, Paso: 100/600, Perdida: 1.14959\n",
      "Epoca: 5/5, Paso: 200/600, Perdida: 1.03604\n",
      "Epoca: 5/5, Paso: 300/600, Perdida: 1.03775\n",
      "Epoca: 5/5, Paso: 400/600, Perdida: 1.02483\n",
      "Epoca: 5/5, Paso: 500/600, Perdida: 1.02641\n",
      "Epoca: 5/5, Paso: 600/600, Perdida: 0.92829\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torchvision.datasets import MNIST\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import ToTensor\n",
    "from modelos import RegresionMultinomial\n",
    "\n",
    "# Se verifica si esta disponible CUDA,en caso contraro se usa el procesador\n",
    "device = torch.device('cuda'if torch.cuda.is_available() else'cpu')\n",
    "\n",
    "# Hiper-parametros\n",
    "input_size = 784 # Dimension de datos de entrada (28 x 28)\n",
    "num_classes = 10 # MNIST tiene 10 clases (numeros del 1 al 10)\n",
    "num_epochs = 5 # Numero de epocas para entrenar\n",
    "bs = 100 # Tamano de lote (batch_size)\n",
    "lr = 0.001 # Tasa de aprendizaje\n",
    "\n",
    "# Se bajan los datos MINST\n",
    "\n",
    "root ='./datos'# Carpeta donde se guardaran los datos\n",
    "train_data = MNIST(root, train=True, transform=ToTensor(), download=True)\n",
    "test_data  = MNIST(root, train=False, transform=ToTensor())\n",
    "\n",
    "# Se crea el iterable sobre el dataset\n",
    "train_loader = DataLoader(train_data, batch_size=bs, shuffle=True)\n",
    "test_loader  = DataLoader(test_data,  batch_size=bs, shuffle=False)\n",
    "\n",
    "# ==================\n",
    "# Definimos modelo\n",
    "# ==================\n",
    "\n",
    "# Se define el modelo \n",
    "model = RegresionMultinomial(input_size, num_classes).to(device)\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "\n",
    "# ==================\n",
    "# Optimizacion\n",
    "# ==================\n",
    "\n",
    "# Implementa el gradiente descendiente para la optimizacion\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "\n",
    "# Entrenamiento del modelo\n",
    "for epoch in range(num_epochs):\n",
    "  for i, (xi, yi) in enumerate(train_loader):\n",
    "    \n",
    "    # Las entradas de la imagen se convierten en vectores\n",
    "    xi = xi.reshape(-1, 28*28).to(device)# imagenes\n",
    "    yi = yi.to(device)# etiquetas\n",
    "    \n",
    "    # Propagacion para adelante\n",
    "    output = model(xi)\n",
    "    loss = loss_function(output, yi)\n",
    "    # Propagcion para atras y paso de optimizacion\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if (i+1) % 100 == 0:\n",
    "      print ('Epoca: {}/{}, Paso: {}/{}, Perdida: {:.5f}'.format(epoch+1,num_epochs, i+1, len(train_loader), loss.item()))\n",
    "      \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision del modelo en 10000 imagenes: 83.13\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "  correct = 0\n",
    "  total = 0\n",
    "  for xi, yi in test_loader:\n",
    "    # Las entradas de la imagen se convierten en vectores\n",
    "    xi = xi.reshape(-1, 28*28).to(device)\n",
    "    yi = yi.to(device)\n",
    "    \n",
    "    # Se hacen las predicciones\n",
    "    output = model(xi)\n",
    "    _, predicted = torch.max(output.data, 1)\n",
    "    \n",
    "    total += yi.size(0)\n",
    "    correct += (predicted == yi).sum().item()\n",
    "    \n",
    "  print(f'Precision del modelo en {total} imagenes: {100 * correct / total}')\n",
    "\n",
    "des = []\n",
    "des.append(100 * correct / total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Incluya en su archivomodelos.pyla siguiente clase que implementa una red neuronal conuna capa escondidayactivaciones sigmoide. Rellene los comentarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RedNeuronal(nn.Module):\n",
    "  def __init__(self, input_size, num_classes):\n",
    "    \n",
    "    #Se definene las condiciones iniciales\n",
    "    super(RedNeuronal, self).__init__()\n",
    "    \n",
    "    # La capa oculta es de 500 unidades\n",
    "    hidden_size = 500\n",
    "    \n",
    "    # Se usa una función e activación sigmoide\n",
    "    self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "    self.sigmoid = nn.Sigmoid()\n",
    "    self.fc2 = nn.Linear(hidden_size, num_classes)\n",
    "    \n",
    "  def forward(self, x):\n",
    "    out = self.fc1(x)\n",
    "    out = self.sigmoid(out)\n",
    "    out = self.fc2(out)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Pruebe el desempeño deRedNeuronaly compare los resultados conRegresionMultinomial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoca: 1/5, Paso: 100/600, Perdida: 2.29962\n",
      "Epoca: 1/5, Paso: 200/600, Perdida: 2.30401\n",
      "Epoca: 1/5, Paso: 300/600, Perdida: 2.29963\n",
      "Epoca: 1/5, Paso: 400/600, Perdida: 2.29037\n",
      "Epoca: 1/5, Paso: 500/600, Perdida: 2.28146\n",
      "Epoca: 1/5, Paso: 600/600, Perdida: 2.27926\n",
      "Epoca: 2/5, Paso: 100/600, Perdida: 2.27537\n",
      "Epoca: 2/5, Paso: 200/600, Perdida: 2.27816\n",
      "Epoca: 2/5, Paso: 300/600, Perdida: 2.27676\n",
      "Epoca: 2/5, Paso: 400/600, Perdida: 2.26693\n",
      "Epoca: 2/5, Paso: 500/600, Perdida: 2.25274\n",
      "Epoca: 2/5, Paso: 600/600, Perdida: 2.25924\n",
      "Epoca: 3/5, Paso: 100/600, Perdida: 2.25174\n",
      "Epoca: 3/5, Paso: 200/600, Perdida: 2.24151\n",
      "Epoca: 3/5, Paso: 300/600, Perdida: 2.25039\n",
      "Epoca: 3/5, Paso: 400/600, Perdida: 2.23944\n",
      "Epoca: 3/5, Paso: 500/600, Perdida: 2.26194\n",
      "Epoca: 3/5, Paso: 600/600, Perdida: 2.22747\n",
      "Epoca: 4/5, Paso: 100/600, Perdida: 2.24413\n",
      "Epoca: 4/5, Paso: 200/600, Perdida: 2.22414\n",
      "Epoca: 4/5, Paso: 300/600, Perdida: 2.21918\n",
      "Epoca: 4/5, Paso: 400/600, Perdida: 2.22984\n",
      "Epoca: 4/5, Paso: 500/600, Perdida: 2.19777\n",
      "Epoca: 4/5, Paso: 600/600, Perdida: 2.21748\n",
      "Epoca: 5/5, Paso: 100/600, Perdida: 2.20988\n",
      "Epoca: 5/5, Paso: 200/600, Perdida: 2.20910\n",
      "Epoca: 5/5, Paso: 300/600, Perdida: 2.20363\n",
      "Epoca: 5/5, Paso: 400/600, Perdida: 2.18813\n",
      "Epoca: 5/5, Paso: 500/600, Perdida: 2.20500\n",
      "Epoca: 5/5, Paso: 600/600, Perdida: 2.19602\n"
     ]
    }
   ],
   "source": [
    "from modelos import RedNeuronal\n",
    "\n",
    "\n",
    "# Se define el modelo \n",
    "model = RedNeuronal(input_size, num_classes).to(device)\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "\n",
    "# ==================\n",
    "# Optimizacion\n",
    "# ==================\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "\n",
    "# Entrenamiento del modelo\n",
    "for epoch in range(num_epochs):\n",
    "  for i, (xi, yi) in enumerate(train_loader):\n",
    "    \n",
    "    xi = xi.reshape(-1, 28*28).to(device)# imagenes\n",
    "    yi = yi.to(device)# etiquetas\n",
    "    \n",
    "    # Propagacion para adelante\n",
    "    output = model(xi)\n",
    "    loss = loss_function(output, yi)\n",
    "    # Propagcion para atras y paso de optimizacion\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if (i+1) % 100 == 0:\n",
    "      print ('Epoca: {}/{}, Paso: {}/{}, Perdida: {:.5f}'.format(epoch+1,num_epochs, i+1, len(train_loader), loss.item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probamos el desempeño del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision del modelo en 10000 imagenes: 45.0\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "  correct = 0\n",
    "  total = 0\n",
    "  for xi, yi in test_loader:\n",
    "    # [COMENTARIO]\n",
    "    xi = xi.reshape(-1, 28*28).to(device)\n",
    "    yi = yi.to(device)\n",
    "    \n",
    "    # [COMENTARIO]\n",
    "    output = model(xi)\n",
    "    _, predicted = torch.max(output.data, 1)\n",
    "    \n",
    "    total += yi.size(0)\n",
    "    correct += (predicted == yi).sum().item()\n",
    "    \n",
    "  print(f'Precision del modelo en {total} imagenes: {100 * correct / total}')\n",
    "des.append(100 * correct / total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El desempeño es mucho peor que el que no tiene capa oculta."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Considere las siguientes arquitecturas de redes neuronales:\n",
    "\n",
    "a)RedNeuronal: Una capa escondida con 500 unidades (la que ya tenemos).\n",
    "\n",
    "b)RedNeuronal3: Tres capas escondidas de 500, 100 y 30 unidades.\n",
    "\n",
    "c)RedNeuronal5: Cinco capas escondidas de 500, 300, 100, 50, 30 unidades.Experimente cómo cambia el desempeño en cada uno de estos modelos al variar las funciones de activación y eloptimizador. Al hacer esto:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoca: 1/5, Paso: 100/600, Perdida: 2.30958\n",
      "Epoca: 1/5, Paso: 200/600, Perdida: 2.30008\n",
      "Epoca: 1/5, Paso: 300/600, Perdida: 2.30023\n",
      "Epoca: 1/5, Paso: 400/600, Perdida: 2.28431\n",
      "Epoca: 1/5, Paso: 500/600, Perdida: 2.29353\n",
      "Epoca: 1/5, Paso: 600/600, Perdida: 2.29980\n",
      "Epoca: 2/5, Paso: 100/600, Perdida: 2.30310\n",
      "Epoca: 2/5, Paso: 200/600, Perdida: 2.29923\n",
      "Epoca: 2/5, Paso: 300/600, Perdida: 2.28596\n",
      "Epoca: 2/5, Paso: 400/600, Perdida: 2.27811\n",
      "Epoca: 2/5, Paso: 500/600, Perdida: 2.27193\n",
      "Epoca: 2/5, Paso: 600/600, Perdida: 2.25072\n",
      "Epoca: 3/5, Paso: 100/600, Perdida: 2.26841\n",
      "Epoca: 3/5, Paso: 200/600, Perdida: 2.26983\n",
      "Epoca: 3/5, Paso: 300/600, Perdida: 2.27412\n",
      "Epoca: 3/5, Paso: 400/600, Perdida: 2.26427\n",
      "Epoca: 3/5, Paso: 500/600, Perdida: 2.25572\n",
      "Epoca: 3/5, Paso: 600/600, Perdida: 2.27360\n",
      "Epoca: 4/5, Paso: 100/600, Perdida: 2.24276\n",
      "Epoca: 4/5, Paso: 200/600, Perdida: 2.24379\n",
      "Epoca: 4/5, Paso: 300/600, Perdida: 2.25100\n",
      "Epoca: 4/5, Paso: 400/600, Perdida: 2.23689\n",
      "Epoca: 4/5, Paso: 500/600, Perdida: 2.22715\n",
      "Epoca: 4/5, Paso: 600/600, Perdida: 2.23462\n",
      "Epoca: 5/5, Paso: 100/600, Perdida: 2.23221\n",
      "Epoca: 5/5, Paso: 200/600, Perdida: 2.20681\n",
      "Epoca: 5/5, Paso: 300/600, Perdida: 2.19676\n",
      "Epoca: 5/5, Paso: 400/600, Perdida: 2.20549\n",
      "Epoca: 5/5, Paso: 500/600, Perdida: 2.20519\n",
      "Epoca: 5/5, Paso: 600/600, Perdida: 2.19132\n",
      "Precision del modelo en 10000 imagenes: 52.63\n"
     ]
    }
   ],
   "source": [
    "from modelos import RedNeuronal3\n",
    "\n",
    "\n",
    "# Se define el modelo \n",
    "model = RedNeuronal3(input_size, num_classes).to(device)\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "\n",
    "# ==================\n",
    "# Optimizacion\n",
    "# ==================\n",
    "\n",
    "# [COMENTARIO]\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "\n",
    "# Entrenamiento del modelo\n",
    "for epoch in range(num_epochs):\n",
    "  for i, (xi, yi) in enumerate(train_loader):\n",
    "    \n",
    "    # [COMENTARIO]\n",
    "    xi = xi.reshape(-1, 28*28).to(device)# imagenes\n",
    "    yi = yi.to(device)# etiquetas\n",
    "    \n",
    "    # Propagacion para adelante\n",
    "    output = model(xi)\n",
    "    loss = loss_function(output, yi)\n",
    "    # Propagcion para atras y paso de optimizacion\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if (i+1) % 100 == 0:\n",
    "      print ('Epoca: {}/{}, Paso: {}/{}, Perdida: {:.5f}'.format(epoch+1,num_epochs, i+1, len(train_loader), loss.item()))\n",
    "      \n",
    "# Prueba del modelo\n",
    "# Al probar, usamos torch.no_grad() porque [COMENTARIO]\n",
    "with torch.no_grad():\n",
    "  correct = 0\n",
    "  total = 0\n",
    "  for xi, yi in test_loader:\n",
    "    # [COMENTARIO]\n",
    "    xi = xi.reshape(-1, 28*28).to(device)\n",
    "    yi = yi.to(device)\n",
    "    \n",
    "    # [COMENTARIO]\n",
    "    output = model(xi)\n",
    "    _, predicted = torch.max(output.data, 1)\n",
    "    \n",
    "    total += yi.size(0)\n",
    "    correct += (predicted == yi).sum().item()\n",
    "    \n",
    "  print(f'Precision del modelo en {total} imagenes: {100 * correct / total}')\n",
    "des.append(100 * correct / total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora construyamos el modelo con 5 capas escondidas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoca: 1/5, Paso: 100/600, Perdida: 2.28778\n",
      "Epoca: 1/5, Paso: 200/600, Perdida: 2.31950\n",
      "Epoca: 1/5, Paso: 300/600, Perdida: 2.31355\n",
      "Epoca: 1/5, Paso: 400/600, Perdida: 2.29777\n",
      "Epoca: 1/5, Paso: 500/600, Perdida: 2.29374\n",
      "Epoca: 1/5, Paso: 600/600, Perdida: 2.30349\n",
      "Epoca: 2/5, Paso: 100/600, Perdida: 2.29980\n",
      "Epoca: 2/5, Paso: 200/600, Perdida: 2.30542\n",
      "Epoca: 2/5, Paso: 300/600, Perdida: 2.30369\n",
      "Epoca: 2/5, Paso: 400/600, Perdida: 2.30673\n",
      "Epoca: 2/5, Paso: 500/600, Perdida: 2.30756\n",
      "Epoca: 2/5, Paso: 600/600, Perdida: 2.30046\n",
      "Epoca: 3/5, Paso: 100/600, Perdida: 2.31254\n",
      "Epoca: 3/5, Paso: 200/600, Perdida: 2.30370\n",
      "Epoca: 3/5, Paso: 300/600, Perdida: 2.28896\n",
      "Epoca: 3/5, Paso: 400/600, Perdida: 2.30301\n",
      "Epoca: 3/5, Paso: 500/600, Perdida: 2.29762\n",
      "Epoca: 3/5, Paso: 600/600, Perdida: 2.29109\n",
      "Epoca: 4/5, Paso: 100/600, Perdida: 2.29541\n",
      "Epoca: 4/5, Paso: 200/600, Perdida: 2.29527\n",
      "Epoca: 4/5, Paso: 300/600, Perdida: 2.28702\n",
      "Epoca: 4/5, Paso: 400/600, Perdida: 2.29964\n",
      "Epoca: 4/5, Paso: 500/600, Perdida: 2.29599\n",
      "Epoca: 4/5, Paso: 600/600, Perdida: 2.28900\n",
      "Epoca: 5/5, Paso: 100/600, Perdida: 2.29414\n",
      "Epoca: 5/5, Paso: 200/600, Perdida: 2.28229\n",
      "Epoca: 5/5, Paso: 300/600, Perdida: 2.27728\n",
      "Epoca: 5/5, Paso: 400/600, Perdida: 2.29110\n",
      "Epoca: 5/5, Paso: 500/600, Perdida: 2.28576\n",
      "Epoca: 5/5, Paso: 600/600, Perdida: 2.28553\n",
      "Precision del modelo en 10000 imagenes: 19.83\n"
     ]
    }
   ],
   "source": [
    "class RedNeuronal5(nn.Module):\n",
    "  def __init__(self, input_size, num_classes):\n",
    "    \n",
    "    super(RedNeuronal5, self).__init__()\n",
    "    \n",
    "    hidden_size1 = 500\n",
    "    hidden_size2 = 300\n",
    "    hidden_size3 = 100\n",
    "    hidden_size4 = 50\n",
    "    hidden_size5 = 30\n",
    "    \n",
    "    # [COMENTARIO]\n",
    "    self.fc1 = nn.Linear(input_size, hidden_size1)\n",
    "    self.relu = nn.ReLU()\n",
    "    self.fc2 = nn.Linear(hidden_size1, hidden_size2)\n",
    "    self.fc3 = nn.Linear(hidden_size2, hidden_size3)\n",
    "    self.fc4 = nn.Linear(hidden_size3, hidden_size4)\n",
    "    self.fc5 = nn.Linear(hidden_size4, hidden_size5)\n",
    "    self.fc6 = nn.Linear(hidden_size5, num_classes)\n",
    "    \n",
    "  def forward(self, x):\n",
    "    out = self.fc1(x)\n",
    "    out = self.relu(out)\n",
    "    out = self.fc2(out)\n",
    "    out = self.fc3(out)\n",
    "    out = self.fc4(out)\n",
    "    out = self.fc5(out)\n",
    "    out = self.fc6(out)\n",
    "    return out\n",
    "  \n",
    "\n",
    "\n",
    "# Se define el modelo \n",
    "model = RedNeuronal5(input_size, num_classes).to(device)\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "\n",
    "# ==================\n",
    "# Optimizacion\n",
    "# ==================\n",
    "\n",
    "# [COMENTARIO]\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "\n",
    "# Entrenamiento del modelo\n",
    "for epoch in range(num_epochs):\n",
    "  for i, (xi, yi) in enumerate(train_loader):\n",
    "    \n",
    "    # [COMENTARIO]\n",
    "    xi = xi.reshape(-1, 28*28).to(device)# imagenes\n",
    "    yi = yi.to(device)# etiquetas\n",
    "    \n",
    "    # Propagacion para adelante\n",
    "    output = model(xi)\n",
    "    loss = loss_function(output, yi)\n",
    "    # Propagcion para atras y paso de optimizacion\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if (i+1) % 100 == 0:\n",
    "      print ('Epoca: {}/{}, Paso: {}/{}, Perdida: {:.5f}'.format(epoch+1,num_epochs, i+1, len(train_loader), loss.item()))\n",
    "      \n",
    "# Prueba del modelo\n",
    "# Al probar, usamos torch.no_grad() porque [COMENTARIO]\n",
    "with torch.no_grad():\n",
    "  correct = 0\n",
    "  total = 0\n",
    "  for xi, yi in test_loader:\n",
    "    # [COMENTARIO]\n",
    "    xi = xi.reshape(-1, 28*28).to(device)\n",
    "    yi = yi.to(device)\n",
    "    \n",
    "    # [COMENTARIO]\n",
    "    output = model(xi)\n",
    "    _, predicted = torch.max(output.data, 1)\n",
    "    \n",
    "    total += yi.size(0)\n",
    "    correct += (predicted == yi).sum().item()\n",
    "    \n",
    "  print(f'Precision del modelo en {total} imagenes: {100 * correct / total}')\n",
    "des.append(100 * correct / total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.bar(['RegMult','RN','RN3','RN5'],des)\n",
    "plt.ylabel('Precisió del modelo')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Trucos para entrenar redes neuronales\n",
    "\n",
    "## 1.1 Tasa de aprendizaje\n",
    "\n",
    "La clase pasada entrenamos una red neuronal usando el optimizador SGD y el optimizador Adam.\n",
    "\n",
    "1. Implemente las siguientes funciones para computar la precisión y la pérdida sobre los datos de entrenamiento y\n",
    "validación (Note que debe completar la definición de la función y comentar donde se indica)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torchvision.datasets import MNIST\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "def precision(prueba=True):\n",
    "  loader = test_loader if prueba else train_loader\n",
    "  total=0\n",
    "  correct=0\n",
    "  with torch.no_grad():\n",
    "    for xi, yi in loader:\n",
    "      xi = xi.reshape(-1, 28*28).to(device)\n",
    "      yi = yi.to(device)\n",
    "      output = model(xi)\n",
    "      _, predicted = torch.max(output.data, 1)\n",
    "      total += yi.size(0)\n",
    "      correct += (predicted == yi).sum().item()\n",
    "  return correct/total\n",
    "\n",
    "def perdida(prueba=True):\n",
    "  trainset_loss = 0.0\n",
    "  loader = test_loader if prueba else train_loader\n",
    "  with torch.no_grad():\n",
    "    for xi, yi in loader:\n",
    "      xi = xi.reshape(-1, 28*28).to(device)\n",
    "      yi = yi.to(device)\n",
    "      output = model(xi)\n",
    "      loss = loss_function(output, yi)\n",
    "\n",
    "    batch_loss = loss.item() * yi.size(0)\n",
    "    trainset_loss += batch_loss\n",
    "  return trainset_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Entrene una red neuronal profunda con dos capas escondidas (de 200 y 60 unidades) y activaciones nn.ReLU. Optimice utilizando Adam con una una tasa de aprendizaje lr=0.001. Al entrenar grafique la pérdida y el error de precisión."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero definimos el modelo correspondiente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NNh2_relu(nn.Module):\n",
    "    def __init__(self, input_size, num_classes):\n",
    "        super(NNh2_relu, self).__init__()\n",
    "\n",
    "        hidden_size1, hidden_size2  = 200, 60\n",
    "\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size1)\n",
    "        self.fc2 = nn.Linear(hidden_size1, hidden_size2)\n",
    "        self.fc3 = nn.Linear(hidden_size2, num_classes)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.relu(self.fc1(x))\n",
    "        out = self.relu(self.fc2(out))\n",
    "        out = self.relu(self.fc3(out))\n",
    "        return out"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "A continuación definimos los hiperparámetros, el optimizador Adam  y la función de perdida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 784 # Dimension de datos de entrada (28 x 28)\n",
    "num_classes = 10 # MNIST tiene 10 clases (numeros del 1 al 10)\n",
    "num_epochs = 10 # Numero de epocas para entrenar\n",
    "bs = 100 # Tamano de lote (batch_size)\n",
    "\n",
    "lr = 0.001 # Tasa de aprendizaje\n",
    "\n",
    "model = NNh2_relu(input_size, num_classes)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "loss_function = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora entrenaremos el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

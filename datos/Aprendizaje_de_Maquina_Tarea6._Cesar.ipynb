{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aprendizaje de Máquina - Tarea 6\n",
    "\n",
    "**Alumno:** César Zamora Martínez\n",
    " **Fecha:** 19 de Noviembre de 2019 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio 1.3 Redes de múltiples capas para clasificación\n",
    "\n",
    "Demuestre que\n",
    "$$ \\nabla_{ a^{(L+1)} (x)} l(f (\\mathbf{x}), y) = − (e(y) − f (x)) $$\n",
    "Donde $e(y) \\in  \\mathbb{R}$ m es un vector tal que $e(y)_i = 1_{y = i}$.\n",
    "\n",
    "**Pendiente: Desarrollo**\n",
    "\n",
    "Para ello debemos notar que $$\\mathcal{l}(f(x),y) =  -\\log(f(x)_y)  =  -\\log(softmax(y, a^{(L+1)}(x))) = \\log( \\sum_i exp({a^{(L+1)} (x)_i}) - a^{(L+1)}(x)_y  $$\n",
    "\n",
    "De dicha observación se desprende que:\n",
    "\n",
    "$$ \\frac{ \\partial }{ \\partial a^{(L+1)} (x)_i } \\mathcal{l}(f(x),y) = \\begin{cases} \\frac{ exp({a^{(L+1)} (x)_y}) }{\\sum_i exp({a^{(L+1)} (x)_i})} - 1 & i=y \\\\ \\frac{ exp({a^{(L+1)} (x)_y}) }{\\sum_i exp({a^{(L+1)} (x)_i})}  & i\\neq y \\end{cases}$$\n",
    "\n",
    "$$ =  \\begin{cases} softmax(y, a^{(L+1)}(x)) + 1 & i=y \\\\ softmax(y, a^{(L+1)}(x))  & i\\neq y \\end{cases} $$\n",
    "\n",
    "$$ =  softmax(y, a^{(L+1)}(x)) + 1_{y = i} = softmax(y, a^{(L+1)}(x))- e(y) =   − (e(y) − f(\\mathbf{x})) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Clasificación con MNIST\n",
    " \n",
    "### Ejercicio 2.4\n",
    "\n",
    "El archivo correspondiente a la implementación  se denominó **modelos.py**, que como parte de si despliega la siguiente implementación. **Nota:** el código propuesto en la tarea no contiene ningún marcador de tipo comentario, sin embargo se han añadido comentarios para describir su funcionamiento:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "# ==================\n",
    "# Regresion logistica multinomial\n",
    "# ==================\n",
    "class RegresionMultinomial(nn.Module):\n",
    "    def __init__(self, input_size, num_classes):\n",
    "        super(RegresionMultinomial, self).__init__() # Metodo para que la clase RegresionMultinomial herede atributos y metodos de clases hijas de nn.Module\n",
    "        self.linear = nn.Linear(input_size, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.linear(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio 2.5\n",
    "a) Llene las líneas de [COMENTARIO] indicadas.\n",
    "\n",
    "A continuación se presenta la implementación del programa **regresion_multinomial.py**, que contiene la implementación para el método de regresión logística multinomial incorporando comentarios que precisar su funcionamiento:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torchvision.datasets import MNIST\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import ToTensor\n",
    "from modelos import RegresionMultinomial\n",
    "\n",
    "# Permite realizar emplear una tarjeta GPU de Nvida a traves de CUDA\n",
    "# En caso de que el equipo no cuente con tal hardware, el proceso de \n",
    "# estimacion se lleva a cabo en el cpu del equipo huesped\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Hiper-parametros\n",
    "input_size = 784 # Dimension de datos de entrada (28 x 28)\n",
    "num_classes = 10 # MNIST tiene 10 clases (numeros del 1 al 10)\n",
    "num_epochs = 5 # Numero de epocas para entrenar\n",
    "bs = 100 # Tamano de lote (batch_size)\n",
    "lr = 0.001 # Tasa de aprendizaje\n",
    "\n",
    "# Cadena de texto para indicar el directorio en donde se guardaran los\n",
    "# datos en lo que se basara el modelo de prediccion (es decir,\n",
    "# tanto datos en crudo como los resultados del procesamiento). \n",
    "# La carpeta se creo previamente con el comandor mkdir\n",
    "root = './datos'\n",
    "# Carpeta donde se guardaran los datos\n",
    "train_data = MNIST(root, train=True, transform=ToTensor(), download=True)\n",
    "test_data = MNIST(root, train=False, transform=ToTensor())\n",
    "\n",
    "# Se cargan los datos que serviran como entrenamiento y prueba empleando\n",
    "# la funcion DataLoader. Esta permite realizar cargas por lotes de un \n",
    "# tamano especifico (batch_size), indicando si se emplean o no un metodo\n",
    "# de reemplazo (shuffle), de acuerdo con la documentacion:\n",
    "# https://pytorch.org/docs/stable/_modules/torch/utils/data/dataloader.html\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=bs, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=bs, shuffle=False)\n",
    "\n",
    "# ==================\n",
    "# Definimos modelo\n",
    "# ==================\n",
    "# Instancia la clase del modelo de red a modelar (importada del archivo\n",
    "# models.py), junto con el tamano de sus datos de entrada y numero de clases\n",
    "# para el problema de clasificacion. En adicion, se establece el tipo de funcion\n",
    "#  de perdida que se considerara en el problema de prediccion para establecer\n",
    "# la funcion de riesgo (empirico)\n",
    "\n",
    "# En este caso, se emplea  un modelo de regresion multinomial \n",
    "# junto con la implementacion de PyTorch de la entropia cruzada\n",
    "\n",
    "model = RegresionMultinomial(input_size, num_classes).to(device)\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "\n",
    "# ==================\n",
    "# Optimizacion\n",
    "# ==================\n",
    "# Metodo con el que se realiza la optimizacion de los parametros de la red\n",
    "# Es este caso de emplea la imlpementacion del descenso de gradiente estocastico\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "# Entrenamiento del modelo\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (xi, yi) in enumerate(train_loader):\n",
    "\n",
    "        # Las imagenes y correspondientes etiquetas para su clasificacion en el conjunto de\n",
    "\t# entrenamiento se envian con cuda al dipositivo GPU  correspondiente, \n",
    "\t#o en caso contrario se procesan en el CPU del equipo huesped\n",
    "        xi = xi.reshape(-1, 28*28).to(device) # imagenes\n",
    "        yi = yi.to(device) # etiquetas\n",
    "\n",
    "        # Propagacion para adelante\n",
    "        output = model(xi)\n",
    "        loss = loss_function(output, yi)\n",
    "\n",
    "        # Propagacion para atras y paso de optimizacion\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if (i+1) % 100 == 0:\n",
    "            print('Epoca: {}/{}, Paso: {}/{}, Perdida: {:.5f}'.format(epoch+1,num_epochs, i+1, len(train_loader), loss.item()))\n",
    "\n",
    "\n",
    "# Prueba del modelo\n",
    "# Al probar, usamos torch.no_grad() porque le decimos autograd que no guarde registro de \n",
    "# estas operaciones, al no formar parte del proceso de optimización del modelo, sino \n",
    "# de probar su nivel de prediccion\n",
    "# Ver: https://pytorch.org/tutorials/beginner/blitz/autograd_tutorial.html#gradients\n",
    "\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for xi, yi in test_loader:\n",
    "\n",
    "        # Nuevamente, imagenes y correspondientes etiquetas para su clasificacion\n",
    "\t# pertenecientes al conjunto de prueba se envian con cuda al dipositivo\n",
    "\t# GPU  correspondiente, o en caso contrario\n",
    "        # se procesan en el CPU del equipo huesped\n",
    "\n",
    "        xi = xi.reshape(-1,28*28).to(device)\n",
    "        yi = yi.to(device)\n",
    "\n",
    "        # Con el modelo entrenado, se predice la etiqueta de cada imagen xi en el conjunto\n",
    "\t# de prueba, y se cuente para cuantos de estos la etiqueta predecida corresponde\n",
    "\t# con el valor real. Dicha variable de calcula de manera iterativa para imprimir\n",
    "\t# finalmente el porcentaje de etiquetas correctamente predichas por el modelo.\n",
    "        output = model(xi)\n",
    "        _, predicted = torch.max(output.data, 1)\n",
    "\n",
    "        total += yi.size(0)\n",
    "        correct += (predicted == yi).sum().item()\n",
    "\n",
    "    print(f'Precision del modelo en {total} imagenes: {100 * correct / total}')\n",
    "\n",
    "\n",
    "# Permite  escibrir en disco (a traves de un diccionario) al modelo que se \n",
    "# establecido con los datos cargados en un archivo de formato .ckpt denomiado \"modelo\"\n",
    "save_model = False\n",
    "if save_model is True:\n",
    "    torch.save(model.state_dict(), 'modelo.ckpt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Nota:**\n",
    "\n",
    "Antes de proseguir en los argumentos de solución a esta tarea, cabe destacar que a efecto de extender el código proporcionado para las redes recié presentadas para todas las redes que se abordan en esta tarea, al código de **modelos.py** se añadieron clases que permiten representar la regresión logística multinomila bajo los métodos de optimización SGD y Adam, así como las siguientes redes 1) RedNeuronal: Una capa escondida con 500 unidades (la que ya tenemos),  2) RedNeuronal3: Tres capas escondidas de 500, 100 y 30 unidades, 3) RedNeuronal5: Cinco capas escondidas de 500, 300, 100, 50, 30 unidades, considerando las posibles variaciones de estas al combinarlas con funciones de activación de tipo sigmoide y ReLU, así como cambiando los métodos de optimización empleados para poder escoger entre SGD y Adam.\n",
    "\n",
    "Al respecto, la ampliación del archivo **modelos.py** es la siguiente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "# ==================\n",
    "# Regresion logistica multinomial\n",
    "# ==================\n",
    "class RegresionMultinomial(nn.Module):\n",
    "    def __init__(self, input_size, num_classes):\n",
    "        super(RegresionMultinomial, self).__init__()\n",
    "        self.linear = nn.Linear(input_size, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.linear(x)\n",
    "        return out\n",
    "\n",
    "# ==================\n",
    "# Red neuronal de 1 capa escondida con activaciones Sigm\n",
    "# ==================\n",
    "class RedNeuronal_Sigm(nn.Module):\n",
    "    def __init__(self, input_size, num_classes):\n",
    "        # Permite que la clase  RedNeuronal herede los atributos y metodos de\n",
    "        # las clases hijas de la clase nn.Module al ser construida\n",
    "        super(RedNeuronal_Sigm, self).__init__()\n",
    "\n",
    "        # unidad de capa escondida\n",
    "        hidden_size = 500\n",
    "\n",
    "        # funciones de pre-activacion y activacion en capa escondida (linea-sigmoide-lineal)\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.fc2 = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.sigmoid(out)\n",
    "        out = self.fc2(out)\n",
    "        return out\n",
    "\n",
    "# ==================\n",
    "# Red neuronal de 1 capa escondida con activaciones ReLU\n",
    "# ==================\n",
    "class RedNeuronal_ReLU(nn.Module):\n",
    "    def __init__(self, input_size, num_classes):\n",
    "        # Permite que la clase  RedNeuronal herede los atributos y metodos de\n",
    "        # las clases hijas de la clase nn.Module al ser construida\n",
    "        super(RedNeuronal_ReLU, self).__init__()\n",
    "\n",
    "        # unidad de capa escondida\n",
    "        hidden_size = 500\n",
    "\n",
    "        # funciones de pre-activacion y activacion en capa escondida (linea-sigmoide-lineal)\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        return out \n",
    "    \n",
    "# ==================\n",
    "# Red neuronal de 3 capas escondidas con activaciones Sigm\n",
    "# ==================\n",
    "class RedNeuronal3_Sigm(nn.Module):\n",
    "    def __init__(self, input_size, num_classes):\n",
    "        # Permite que la clase  RedNeuronal herede los atributos y metodos de\n",
    "        # las clases hijas de la clase nn.Module al ser construida\n",
    "        super(RedNeuronal3_Sigm, self).__init__()\n",
    "\n",
    "        # unidades de capas escondidas\n",
    "        hidden_size1, hidden_size2, hidden_size3  = 500, 100, 30\n",
    "\n",
    "        # funciones de pre-activacion y activacion en capa escondida (linea-sigmoide-lineal)\n",
    "        self.fc1= nn.Linear(input_size, hidden_size1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.fc2 = nn.Linear(hidden_size1, hidden_size2)\n",
    "        self.fc3 = nn.Linear(hidden_size2, hidden_size3)\n",
    "        self.fc4 = nn.Linear(hidden_size3, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.sigmoid(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.sigmoid(out)\n",
    "        out = self.fc3(out)\n",
    "        out = self.sigmoid(out)\n",
    "        out = self.fc4(out)\n",
    "        return out\n",
    "    \n",
    "    \n",
    "# ==================\n",
    "# Red neuronal de 3 capas escondidas con activaciones ReLU\n",
    "# ==================\n",
    "class RedNeuronal3_ReLU(nn.Module):\n",
    "    def __init__(self, input_size, num_classes):\n",
    "        # Permite que la clase  RedNeuronal herede los atributos y metodos de\n",
    "        # las clases hijas de la clase nn.Module al ser construida\n",
    "        super(RedNeuronal3_ReLU, self).__init__()\n",
    "\n",
    "        # unidades de capas escondidas\n",
    "        hidden_size1, hidden_size2, hidden_size3  = 500, 100, 30\n",
    "\n",
    "        # funciones de pre-activacion y activacion en capa escondida (linea-sigmoide-lineal)\n",
    "        self.fc1= nn.Linear(input_size, hidden_size1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size1, hidden_size2)\n",
    "        self.fc3 = nn.Linear(hidden_size2, hidden_size3)\n",
    "        self.fc4 = nn.Linear(hidden_size3, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc3(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc4(out)\n",
    "        return out\n",
    "\n",
    "# ==================\n",
    "# Red neuronal de 5 capas escondidas con activaciones Sigm\n",
    "# ==================\n",
    "class RedNeuronal5_Sigm(nn.Module):\n",
    "    def __init__(self, input_size, num_classes):\n",
    "    # Permite que la clase  RedNeuronal herede los atributos y metodos de\n",
    "    # las clases hijas de la clase nn.Module al ser construida\n",
    "        super(RedNeuronal5_Sigm, self).__init__()\n",
    "\n",
    "        # unidades de capas escondidas\n",
    "        hidden_size1, hidden_size2, hidden_size3,hidden_size4, hidden_size5  = 500, 300, 100, 50, 30\n",
    "\n",
    "        # funciones de pre-activacion y activacion en capa escondida\n",
    "        self.fc1, self.sigmoid = nn.Linear(input_size, hidden_size1), nn.Sigmoid()\n",
    "        self.fc2 = nn.Linear(hidden_size1, hidden_size2)\n",
    "        self.fc3 = nn.Linear(hidden_size2, hidden_size3)\n",
    "        self.fc4 = nn.Linear(hidden_size3, hidden_size4)\n",
    "        self.fc5 = nn.Linear(hidden_size4,  hidden_size5)\n",
    "        self.fc6 = nn.Linear(hidden_size5, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.sigmoid(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.sigmoid(out)\n",
    "        out = self.fc3(out)\n",
    "        out = self.sigmoid(out)\n",
    "        out = self.fc4(out)\n",
    "        out = self.sigmoid(out)\n",
    "        out = self.fc5(out)\n",
    "        out = self.sigmoid(out)\n",
    "        out = self.fc6(out)\n",
    "        return out\n",
    "\n",
    "# ==================\n",
    "# Red neuronal de 5 capas escondidas con activaciones ReLU\n",
    "# ==================\n",
    "class RedNeuronal5_ReLU(nn.Module):\n",
    "    def __init__(self, input_size, num_classes):\n",
    "    # Permite que la clase  RedNeuronal herede los atributos y metodos de\n",
    "    # las clases hijas de la clase nn.Module al ser construida\n",
    "        super(RedNeuronal5_ReLU, self).__init__()\n",
    "\n",
    "        # unidades de capas escondidas\n",
    "        hidden_size1, hidden_size2, hidden_size3,hidden_size4, hidden_size5  = 500, 300, 100, 50, 30\n",
    "\n",
    "        # funciones de pre-activacion y activacion en capa escondida\n",
    "        self.fc1, self.relu = nn.Linear(input_size, hidden_size1), nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size1, hidden_size2)\n",
    "        self.fc3 = nn.Linear(hidden_size2, hidden_size3)\n",
    "        self.fc4 = nn.Linear(hidden_size3, hidden_size4)\n",
    "        self.fc5 = nn.Linear(hidden_size4,  hidden_size5)\n",
    "        self.fc6 = nn.Linear(hidden_size5, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc3(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc4(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc5(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc6(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El código anterior, se usó como base para poder definir una función que nos permite cambiar fácilmente el tipo de red a considerar (de entre una regresión logística multinomial, una red de una capa, un red de tres capas o una de 5), variando la función de activación (entre una de tipo sigmoide o una ReLU), así como el método de optimización a emplear (basado en SGD o Adam de Pytorch).\n",
    "\n",
    "Al respecto, también se incorporó al método SummaryWriter de Tensorboard de manera que pudiera guardar los archivos de las simulaciones a realizarse y generar dashboard para posterior análisis, quedano como sigue:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importamos el conjunto general de librerias a emplear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:This caffe2 python run does not have GPU support. Will run in CPU only mode.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torchvision.datasets import MNIST # Dataset de digitos\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch.utils.tensorboard import SummaryWriter # Utilidad de tensorboard para generar graficos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Importamos el archivo donde se definieron los modelos de redes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modelos import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Función para correr los diferentes modelos de redes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RunModel(modelo, activacion, optimization_metod, directorio=\"runs/testing\", saving_model = False):\n",
    "    '''    \n",
    "    modelo:str red neuronal a considerar (\"RN1\",\"RN3\",\"RN5\",Reg. Lin. Multi:\"RLM\")        \n",
    "    activacion:str funcion de activacion de las capas de red neuronal a considerar\n",
    "    (\"Sigm\": funcion sigmoide, \"ReLU\": funcion ReLU)\n",
    "    optimization_metod:str Metodo de optimizacion para estimar parametros de la red\n",
    "        (\"SGD\": descenso de gradiente estocatico, \"Adam\": metodo Adam)\n",
    "    directorio:str especificacion del directorio para que tensorboard guarde datos para dashboards\n",
    "    saving_model:Bool especifica si el modelo se debe guardar tras correr simulacion\n",
    "    '''\n",
    "    \n",
    "    # Directorio donde se guardaran objetos de tensorboard para generar dashboard de variables monitoreadas\n",
    "    writer = SummaryWriter(directorio)\n",
    "    running_loss=0\n",
    "\n",
    "    #\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    # Hiper-parametros\n",
    "    input_size = 784  # Dimension de datos de entrada (28 x 28)\n",
    "    num_classes = 10  # MNIST tiene 10 clases (numeros del 1 al 10)\n",
    "    num_epochs = 5  # Numero de epocas para entrenar\n",
    "    bs = 100  # Tamano de lote (batch_size)\n",
    "    lr = 0.001  # Tasa de aprendizaje\n",
    "\n",
    "    #\n",
    "    root = './datos'\n",
    "    # Carpeta donde se guardaran los datos\n",
    "    train_data = MNIST(root, train=True, transform=ToTensor(), download=True)\n",
    "    test_data = MNIST(root, train=False, transform=ToTensor())\n",
    "\n",
    "    #\n",
    "    train_loader = DataLoader(train_data, batch_size=bs, shuffle=True)\n",
    "    test_loader = DataLoader(test_data, batch_size=bs, shuffle=False)\n",
    "\n",
    "    # ==================\n",
    "    # Definimos modelo\n",
    "    # ==================\n",
    "    # Definicion del modelo de red\n",
    "    if modelo == \"RLM\":    \n",
    "        model = RegresionMultinomial(input_size, num_classes).to(device)\n",
    "    if modelo == \"RN1\"  and activacion == \"ReLU\":    \n",
    "        model = RedNeuronal_ReLU(input_size, num_classes).to(device)\n",
    "    if modelo == \"RN1\"  and activacion == \"Sigm\":    \n",
    "        model = RedNeuronal_Sigm(input_size, num_classes).to(device)\n",
    "    if modelo == \"RN3\"  and activacion == \"ReLU\":    \n",
    "        model = RedNeuronal3_ReLU(input_size, num_classes).to(device)\n",
    "    if modelo == \"RN3\"  and activacion == \"Sigm\":    \n",
    "        model = RedNeuronal3_Sigm(input_size, num_classes).to(device)\n",
    "    if modelo == \"RN5\"  and activacion == \"ReLU\":    \n",
    "        model = RedNeuronal5_ReLU(input_size, num_classes).to(device)\n",
    "    if modelo == \"RN5\"  and activacion == \"Sigm\":    \n",
    "        model = RedNeuronal5_Sigm(input_size, num_classes).to(device)\n",
    "        \n",
    "    loss_function = nn.CrossEntropyLoss()\n",
    "\n",
    "    # ==================\n",
    "    # Optimizacion\n",
    "    # ==================\n",
    "    # \n",
    "    if optimization_metod==\"SGD\":\n",
    "        optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "    if optimization_metod==\"Adam\":\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "        \n",
    "    # Entrenamiento del modelo\n",
    "    for epoch in range(num_epochs):\n",
    "        for i, (xi, yi) in enumerate(train_loader):\n",
    "\n",
    "            # \n",
    "            xi = xi.reshape(-1, 28*28).to(device)  # imagenes\n",
    "            yi = yi.to(device)  # etiquetas\n",
    "\n",
    "            # Propagacion para adelante\n",
    "            output = model(xi)\n",
    "            loss = loss_function(output, yi)\n",
    "\n",
    "            # Propagcion para atras y paso de optimizacion\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss = loss.item()\n",
    "            if (i+1) % 100 == 0:\n",
    "                writer.add_scalar('training loss',running_loss/1000, epoch*len(train_loader)+1)\n",
    "                print('Epoca: {}/{}, Paso: {}/{}, Perdida: {:.5f}'.format(epoch +\n",
    "                                                                          1, num_epochs, i+1, len(train_loader), loss.item()))\n",
    "\n",
    "    # Prueba del modelo\n",
    "    # Al probar, usamos torch.no_grad()\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        for xi, yi in test_loader:\n",
    "            # \n",
    "            xi = xi.reshape(-1, 28*28).to(device)\n",
    "            yi = yi.to(device)\n",
    "\n",
    "            # \n",
    "            output = model(xi)\n",
    "            _, predicted = torch.max(output.data, 1)\n",
    "\n",
    "            total += yi.size(0)\n",
    "            correct += (predicted == yi).sum().item()\n",
    "\n",
    "            writer.add_scalar('precision_modelo',correct/100, total)\n",
    "\n",
    "        print(f'Precision del modelo en {total} imagenes: {100 * correct / total}')\n",
    "\n",
    "\n",
    "    # \n",
    "    save_model = saving_model\n",
    "    if save_model is True:\n",
    "        torch.save(model.state_dict(), 'modelo.ckpt')\n",
    "    \n",
    "    return "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) ¿Cuál es el error de clasificación?\n",
    "\n",
    "Para responder esta pregunta, la función recién presentada se usó para representar un modelo de regresión logística de tipo multinomial, cuyo resultados se presentan a continuación:\n",
    "\n",
    "c) Explique por qué este código implementa el modelo de regresión logística multinomial.\n",
    "\n",
    "De acuerdo a lo visto en la sección 1.3 de la tarea, el modelo de regresión en comento incorporar como función de pérdida a la log-verosimilitud negativa cuya expresión es la de la entropía cruzada\n",
    "\n",
    "$$H(p, q) = −E p [log q] \\mbox{ con } p(c) = 1{y = c} \\mbox{ y } q(c) = Pr[y = c | x, W]$$.\n",
    "\n",
    "En este sentido, de acuerdo a la documentación de Pytorch la función **CrossEntropyLoss** (ver https://pytorch.org/docs/stable/nn.html#torch.nn.CrossEntropyLoss) resulta en la implementación de la función de pérdida de entropía cruza, con lo cual la función de riesgo que se asocia al modelo de la red bajo esta herramienta de PyTorch es justamente la función de pérdida del problema de regresión logística de tipo multinomial.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Regresión logística multinomial + SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoca: 1/5, Paso: 100/600, Perdida: 2.23107\n",
      "Epoca: 1/5, Paso: 200/600, Perdida: 2.09345\n",
      "Epoca: 1/5, Paso: 300/600, Perdida: 2.03219\n",
      "Epoca: 1/5, Paso: 400/600, Perdida: 1.89934\n",
      "Epoca: 1/5, Paso: 500/600, Perdida: 1.89142\n",
      "Epoca: 1/5, Paso: 600/600, Perdida: 1.78481\n",
      "Epoca: 2/5, Paso: 100/600, Perdida: 1.71872\n",
      "Epoca: 2/5, Paso: 200/600, Perdida: 1.65567\n",
      "Epoca: 2/5, Paso: 300/600, Perdida: 1.56736\n",
      "Epoca: 2/5, Paso: 400/600, Perdida: 1.53417\n",
      "Epoca: 2/5, Paso: 500/600, Perdida: 1.54434\n",
      "Epoca: 2/5, Paso: 600/600, Perdida: 1.48852\n",
      "Epoca: 3/5, Paso: 100/600, Perdida: 1.34137\n",
      "Epoca: 3/5, Paso: 200/600, Perdida: 1.38734\n",
      "Epoca: 3/5, Paso: 300/600, Perdida: 1.39153\n",
      "Epoca: 3/5, Paso: 400/600, Perdida: 1.33284\n",
      "Epoca: 3/5, Paso: 500/600, Perdida: 1.29637\n",
      "Epoca: 3/5, Paso: 600/600, Perdida: 1.28410\n",
      "Epoca: 4/5, Paso: 100/600, Perdida: 1.33315\n",
      "Epoca: 4/5, Paso: 200/600, Perdida: 1.23097\n",
      "Epoca: 4/5, Paso: 300/600, Perdida: 1.17208\n",
      "Epoca: 4/5, Paso: 400/600, Perdida: 1.21201\n",
      "Epoca: 4/5, Paso: 500/600, Perdida: 1.18387\n",
      "Epoca: 4/5, Paso: 600/600, Perdida: 1.15170\n",
      "Epoca: 5/5, Paso: 100/600, Perdida: 0.99103\n",
      "Epoca: 5/5, Paso: 200/600, Perdida: 1.12703\n",
      "Epoca: 5/5, Paso: 300/600, Perdida: 1.05442\n",
      "Epoca: 5/5, Paso: 400/600, Perdida: 1.06344\n",
      "Epoca: 5/5, Paso: 500/600, Perdida: 1.02942\n",
      "Epoca: 5/5, Paso: 600/600, Perdida: 1.10521\n",
      "Precision del modelo en 10000 imagenes: 82.85\n"
     ]
    }
   ],
   "source": [
    "RunModel(\"RLM\", \"Sigm\", \"SGD\", 'runs/RLM_SGD', saving_model = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El error de predicción se puede calcular como $(100- 82.85)/100 \\times 100 \\% = 17.15\\%$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio 2.6\n",
    "\n",
    "Incluya en su archivo modelos.py la siguiente clase que implementa una red neuronal con una capa escondida y activaciones sigmoide. Rellene los comentarios;\n",
    "\n",
    "\n",
    "La implementación realizada junto con los comentarios correspondientes se pueden consultar en la ampliación del código de **modelos.py** vista en el ejercicio **2.5**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio 2.7\n",
    "\n",
    "Pruebe el desempeño de RedNeuronal y compare los resultados con RegresionMultinomial.\n",
    "\n",
    "Al respecto, la implementación correspondiente se refiere al uso de la función presentada en 2.5 para laed Neuronal de una capa escondida, con activación de tipo sigmoide y método de optimización SGD, cuyos resultados se presentan en seguida:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Red Neuronal de una capa escondida + Activaciones Sigmoide + SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoca: 1/5, Paso: 100/600, Perdida: 2.31708\n",
      "Epoca: 1/5, Paso: 200/600, Perdida: 2.29881\n",
      "Epoca: 1/5, Paso: 300/600, Perdida: 2.29079\n",
      "Epoca: 1/5, Paso: 400/600, Perdida: 2.28210\n",
      "Epoca: 1/5, Paso: 500/600, Perdida: 2.27837\n",
      "Epoca: 1/5, Paso: 600/600, Perdida: 2.28610\n",
      "Epoca: 2/5, Paso: 100/600, Perdida: 2.27670\n",
      "Epoca: 2/5, Paso: 200/600, Perdida: 2.27217\n",
      "Epoca: 2/5, Paso: 300/600, Perdida: 2.27454\n",
      "Epoca: 2/5, Paso: 400/600, Perdida: 2.27046\n",
      "Epoca: 2/5, Paso: 500/600, Perdida: 2.26060\n",
      "Epoca: 2/5, Paso: 600/600, Perdida: 2.25681\n",
      "Epoca: 3/5, Paso: 100/600, Perdida: 2.25576\n",
      "Epoca: 3/5, Paso: 200/600, Perdida: 2.23885\n",
      "Epoca: 3/5, Paso: 300/600, Perdida: 2.23969\n",
      "Epoca: 3/5, Paso: 400/600, Perdida: 2.24974\n",
      "Epoca: 3/5, Paso: 500/600, Perdida: 2.22979\n",
      "Epoca: 3/5, Paso: 600/600, Perdida: 2.24076\n",
      "Epoca: 4/5, Paso: 100/600, Perdida: 2.22582\n",
      "Epoca: 4/5, Paso: 200/600, Perdida: 2.22268\n",
      "Epoca: 4/5, Paso: 300/600, Perdida: 2.22946\n",
      "Epoca: 4/5, Paso: 400/600, Perdida: 2.22880\n",
      "Epoca: 4/5, Paso: 500/600, Perdida: 2.22459\n",
      "Epoca: 4/5, Paso: 600/600, Perdida: 2.21334\n",
      "Epoca: 5/5, Paso: 100/600, Perdida: 2.22714\n",
      "Epoca: 5/5, Paso: 200/600, Perdida: 2.21252\n",
      "Epoca: 5/5, Paso: 300/600, Perdida: 2.19982\n",
      "Epoca: 5/5, Paso: 400/600, Perdida: 2.18226\n",
      "Epoca: 5/5, Paso: 500/600, Perdida: 2.20851\n",
      "Epoca: 5/5, Paso: 600/600, Perdida: 2.18726\n",
      "Precision del modelo en 10000 imagenes: 44.11\n"
     ]
    }
   ],
   "source": [
    "RunModel(\"RN1\", \"Sigm\", \"SGD\", 'runs/RN1_Sigm_SGD', saving_model = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De manera análoga al ejercicio anterior, ello implica un error de predicción de 55.89%, el cual es casi tres veces mayor al obtenido en el caso de la regresión logística multinomial presentando previamente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio 2.8\n",
    "\n",
    "a) Genere gráficas que muestren el decremento en la función de pérdida y en la precisión sobre los valores de prueba (Puede usar matplotlib o tensorboard). Comente sus observaciones.\n",
    "\n",
    "Para dar respuesta a este ejercicio, se corrieron el resto de modelos correspondientes a las redes RedNeuronal, RedNeuronal3 y RedNeuronal5, variando el método de optimización junto con la función de activación. Los resultados obtenidos se pueden revisar en el Anexo al final del presente documento.\n",
    "\n",
    "Ahora bien, a efecto de falicitar el entendimiento de los siguientes gráficos, se presenta una tabla que resume la notación empleada para nombrar cada modelo de red neuronal, según su tipo, función de activación y método de optimizacion:\n",
    "\n",
    "| Modelo             | Activaciones | Optimizador | Notación |\n",
    "|--------------------|--------------|-----------------|------------------|\n",
    "| RedNeuronal        | ReLU         | SGD       |      RN_ReLU_SGD      |\n",
    "| RedNeuronal        | ReLU         | Adam      |       RN_ReLU_Adam    |\n",
    "| RedNeuronal        | Sigmoid      | SGD       |     RN_Sigm_SGD       |\n",
    "| RedNeuronal        | Sigmoid      | Adam      |       RN_Sigm_Adam    |\n",
    "| RedNeuronal3        | ReLU         | SGD       |      RN3_ReLU_SGD      |\n",
    "| RedNeuronal3        | ReLU         | Adam      |       RN3_ReLU_Adam    |\n",
    "| RedNeuronal3        | Sigmoid      | SGD       |     RN3_Sigm_SGD       |\n",
    "| RedNeuronal3        | Sigmoid      | Adam      |       RN3_Sigm_Adam    |\n",
    "| RedNeuronal5        | ReLU         | SGD       |      RN5_ReLU_SGD      |\n",
    "| RedNeuronal5       | ReLU         | Adam      |       RN5_ReLU_Adam    |\n",
    "| RedNeuronal5        | Sigmoid      | SGD       |     RN5_Sigm_SGD       |\n",
    "| RedNeuronal5        | Sigmoid      | Adam      |       RN5_Sigm_Adam    |\n",
    "\n",
    "**Pérdidas a lo largo de las épocas**\n",
    "\n",
    "A continuación se muestran las gráficas la perdida obtenidas a lo largo de las diferentes épocas. Se puede apreciar que el modelo RN5\\_ReLU\\_Adam fue el que observó un pérdida más baja en las iteraciones consideradas:\n",
    "\n",
    "![Error de entrenamiento a lo largo de las épocas](images/loss.png)\n",
    "![Error de entrenamiento a lo largo de las épocas](images/loss_table.png)\n",
    "\n",
    "Cabe apreciar que los modelos de la RedNeuronal basados en SGD tuvieron las pérdidas más bajas.\n",
    "\n",
    "**Precisión del modelo lo largo de las épocas**\n",
    "\n",
    "A continuación se muestra las gráficas la precisiṕn obtenida pr el modelo al evaluar la predicción de cada elemento del conjunto de prueba contra el dígito correspondiente. Se puede apreciar que el modelo RN1\\_ReLU\\_Adam fue con la mejor precisión (97.94%):\n",
    "\n",
    "![Error de entrenamiento a lo largo de las épocas](images/precision.png)\n",
    "![Error de entrenamiento a lo largo de las épocas](images/precision_table.png)\n",
    "\n",
    "En adición, cabe apreciar que los models de RedNeuronal3 y RedNeuronal5 basados función de activación sigmoide y método de optimización SGD tuvieron la peor predicción con 11.35%.\n",
    "\n",
    "Para complementar este punto, a continuación se presenta un tabla resumen de los valores obtenidos para la precisión en los distintos modelos:\n",
    "\n",
    "**Precisión obtenida con los diferentes modelos**\n",
    "\n",
    "| Modelo             | Activaciones | torch.optim.SGD | torch.optim.Adam |\n",
    "|--------------------|--------------|-----------------|------------------|\n",
    "| RegresionLogistica | -            | 82.85%           | 92.26%            |\n",
    "| RedNeuronal        | ReLU         | 44.11%          | 96.75%            |\n",
    "| RedNeuronal        | Sigmoid      | 78.66%           | 97.74%            |\n",
    "| RedNeuronal3       | ReLU         | 11.35%           | 97.27%            |\n",
    "| RedNeuronal3       | Sigmoid      | 35.21%           | 97.76%            |\n",
    "| RedNeuronal5       | ReLU         | 11.35%           | 97.02%            |\n",
    "| RedNeuronal5       | Sigmoid      | 11.35%           | 97.47%            |\n",
    "\n",
    "Se puede observar como, en términos generales, los modelos de redes neuronales basados en el método de optimización Adam arrojan una precisión alta para este problema de clasificación, independientemente de la función de activación considerada, en contraste con aquellos basados en SGD."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Complete las siguientes tablas.\n",
    "\n",
    "**Error de predicción**\n",
    "\n",
    "\n",
    "|Modelo             | Activaciones | torch.optim.SGD | torch.optim.Adam |\n",
    "|--------------------|--------------|-----------------|------------------|\n",
    "| RegresionLogistica | -            | 17.15%           | 7.74%             |\n",
    "| RedNeuronal        | ReLU         | 57.89%           | 3.25%             |\n",
    "| RedNeuronal        | Sigmoid      | 21.34%           | 2.26%             |\n",
    "| RedNeuronal3       | ReLU         | 88.65%           | 2.73%             |\n",
    "| RedNeuronal3       | Sigmoid      | 64.79%           | 2.24%             |\n",
    "| RedNeuronal5       | ReLU         | 88.65%           | 2.98%             |\n",
    "| RedNeuronal5       | Sigmoid      | 88.65%           | 2.53%             |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio 2.9. \n",
    "\n",
    "¿Qué puede concluir a partir de estos experimentos?\n",
    "\n",
    "Derivado del ejercicio anterior, se pueden presumir los siguientes puntos:\n",
    "\n",
    "* En este problema particular de clasificación, aparentemente Adam es una mejor opción de método de optimización de SGD pues arroja errores de predicción muy bajos al compararse con los obtenidos contra métodos basados en la misma red pero que usan SGD.\n",
    "* Asimismo, la red predice mejor el problema de clasificación de imágenes de dígitos cuando se emplean ReLU que cuando se echa mano de Sigmoid, restringidos al optimizador SGD.\n",
    "* Dicha tendencia se invierte si el método de optimización es Adam.\n",
    "* El desempeño de la predicción con regresión logística multinomial en superado por más de la mitad por los métodos basados en redes neuronales en aquellos casos en los que se usa a Adam como optimizador de los parámetros de la red."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Anexo de resultados de resto de modelos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoca: 1/5, Paso: 100/600, Perdida: 0.84714\n",
      "Epoca: 1/5, Paso: 200/600, Perdida: 0.55226\n",
      "Epoca: 1/5, Paso: 300/600, Perdida: 0.43952\n",
      "Epoca: 1/5, Paso: 400/600, Perdida: 0.58421\n",
      "Epoca: 1/5, Paso: 500/600, Perdida: 0.37473\n",
      "Epoca: 1/5, Paso: 600/600, Perdida: 0.44304\n",
      "Epoca: 2/5, Paso: 100/600, Perdida: 0.44089\n",
      "Epoca: 2/5, Paso: 200/600, Perdida: 0.43384\n",
      "Epoca: 2/5, Paso: 300/600, Perdida: 0.36927\n",
      "Epoca: 2/5, Paso: 400/600, Perdida: 0.28155\n",
      "Epoca: 2/5, Paso: 500/600, Perdida: 0.23258\n",
      "Epoca: 2/5, Paso: 600/600, Perdida: 0.31027\n",
      "Epoca: 3/5, Paso: 100/600, Perdida: 0.26544\n",
      "Epoca: 3/5, Paso: 200/600, Perdida: 0.41425\n",
      "Epoca: 3/5, Paso: 300/600, Perdida: 0.41398\n",
      "Epoca: 3/5, Paso: 400/600, Perdida: 0.28983\n",
      "Epoca: 3/5, Paso: 500/600, Perdida: 0.31366\n",
      "Epoca: 3/5, Paso: 600/600, Perdida: 0.31253\n",
      "Epoca: 4/5, Paso: 100/600, Perdida: 0.42190\n",
      "Epoca: 4/5, Paso: 200/600, Perdida: 0.39038\n",
      "Epoca: 4/5, Paso: 300/600, Perdida: 0.39345\n",
      "Epoca: 4/5, Paso: 400/600, Perdida: 0.33981\n",
      "Epoca: 4/5, Paso: 500/600, Perdida: 0.28323\n",
      "Epoca: 4/5, Paso: 600/600, Perdida: 0.23854\n",
      "Epoca: 5/5, Paso: 100/600, Perdida: 0.28036\n",
      "Epoca: 5/5, Paso: 200/600, Perdida: 0.33646\n",
      "Epoca: 5/5, Paso: 300/600, Perdida: 0.26711\n",
      "Epoca: 5/5, Paso: 400/600, Perdida: 0.27301\n",
      "Epoca: 5/5, Paso: 500/600, Perdida: 0.39146\n",
      "Epoca: 5/5, Paso: 600/600, Perdida: 0.22046\n",
      "Precision del modelo en 10000 imagenes: 92.26\n"
     ]
    }
   ],
   "source": [
    "RunModel(\"RLM\", \"Sigm\", \"Adam\", 'runs/RLM_Adam', saving_model = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Regresión logística multinomial + Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Red Neuronal de una capa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Red Neuronal de una capa escondida + Activaciones ReLU + SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoca: 1/5, Paso: 100/600, Perdida: 2.27098\n",
      "Epoca: 1/5, Paso: 200/600, Perdida: 2.25274\n",
      "Epoca: 1/5, Paso: 300/600, Perdida: 2.21254\n",
      "Epoca: 1/5, Paso: 400/600, Perdida: 2.20317\n",
      "Epoca: 1/5, Paso: 500/600, Perdida: 2.18718\n",
      "Epoca: 1/5, Paso: 600/600, Perdida: 2.17403\n",
      "Epoca: 2/5, Paso: 100/600, Perdida: 2.10185\n",
      "Epoca: 2/5, Paso: 200/600, Perdida: 2.10962\n",
      "Epoca: 2/5, Paso: 300/600, Perdida: 2.01843\n",
      "Epoca: 2/5, Paso: 400/600, Perdida: 2.05426\n",
      "Epoca: 2/5, Paso: 500/600, Perdida: 2.01789\n",
      "Epoca: 2/5, Paso: 600/600, Perdida: 1.98587\n",
      "Epoca: 3/5, Paso: 100/600, Perdida: 1.94279\n",
      "Epoca: 3/5, Paso: 200/600, Perdida: 1.93208\n",
      "Epoca: 3/5, Paso: 300/600, Perdida: 1.88867\n",
      "Epoca: 3/5, Paso: 400/600, Perdida: 1.87086\n",
      "Epoca: 3/5, Paso: 500/600, Perdida: 1.87709\n",
      "Epoca: 3/5, Paso: 600/600, Perdida: 1.78198\n",
      "Epoca: 4/5, Paso: 100/600, Perdida: 1.82296\n",
      "Epoca: 4/5, Paso: 200/600, Perdida: 1.69206\n",
      "Epoca: 4/5, Paso: 300/600, Perdida: 1.70763\n",
      "Epoca: 4/5, Paso: 400/600, Perdida: 1.61053\n",
      "Epoca: 4/5, Paso: 500/600, Perdida: 1.68122\n",
      "Epoca: 4/5, Paso: 600/600, Perdida: 1.61961\n",
      "Epoca: 5/5, Paso: 100/600, Perdida: 1.56045\n",
      "Epoca: 5/5, Paso: 200/600, Perdida: 1.48188\n",
      "Epoca: 5/5, Paso: 300/600, Perdida: 1.45809\n",
      "Epoca: 5/5, Paso: 400/600, Perdida: 1.54109\n",
      "Epoca: 5/5, Paso: 500/600, Perdida: 1.49054\n",
      "Epoca: 5/5, Paso: 600/600, Perdida: 1.41268\n",
      "Precision del modelo en 10000 imagenes: 78.66\n"
     ]
    }
   ],
   "source": [
    "RunModel(\"RN1\", \"ReLU\", \"SGD\", 'runs/RN1_ReLU_SGD', saving_model = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Red Neuronal de una capa escondida + Activaciones Sigmoide + Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoca: 1/5, Paso: 100/600, Perdida: 0.63190\n",
      "Epoca: 1/5, Paso: 200/600, Perdida: 0.24995\n",
      "Epoca: 1/5, Paso: 300/600, Perdida: 0.38825\n",
      "Epoca: 1/5, Paso: 400/600, Perdida: 0.22471\n",
      "Epoca: 1/5, Paso: 500/600, Perdida: 0.31148\n",
      "Epoca: 1/5, Paso: 600/600, Perdida: 0.23046\n",
      "Epoca: 2/5, Paso: 100/600, Perdida: 0.25828\n",
      "Epoca: 2/5, Paso: 200/600, Perdida: 0.14849\n",
      "Epoca: 2/5, Paso: 300/600, Perdida: 0.20679\n",
      "Epoca: 2/5, Paso: 400/600, Perdida: 0.22641\n",
      "Epoca: 2/5, Paso: 500/600, Perdida: 0.22358\n",
      "Epoca: 2/5, Paso: 600/600, Perdida: 0.13848\n",
      "Epoca: 3/5, Paso: 100/600, Perdida: 0.13382\n",
      "Epoca: 3/5, Paso: 200/600, Perdida: 0.20473\n",
      "Epoca: 3/5, Paso: 300/600, Perdida: 0.07089\n",
      "Epoca: 3/5, Paso: 400/600, Perdida: 0.16958\n",
      "Epoca: 3/5, Paso: 500/600, Perdida: 0.10779\n",
      "Epoca: 3/5, Paso: 600/600, Perdida: 0.17531\n",
      "Epoca: 4/5, Paso: 100/600, Perdida: 0.07445\n",
      "Epoca: 4/5, Paso: 200/600, Perdida: 0.06639\n",
      "Epoca: 4/5, Paso: 300/600, Perdida: 0.15601\n",
      "Epoca: 4/5, Paso: 400/600, Perdida: 0.11596\n",
      "Epoca: 4/5, Paso: 500/600, Perdida: 0.08174\n",
      "Epoca: 4/5, Paso: 600/600, Perdida: 0.11613\n",
      "Epoca: 5/5, Paso: 100/600, Perdida: 0.06456\n",
      "Epoca: 5/5, Paso: 200/600, Perdida: 0.04687\n",
      "Epoca: 5/5, Paso: 300/600, Perdida: 0.26638\n",
      "Epoca: 5/5, Paso: 400/600, Perdida: 0.09992\n",
      "Epoca: 5/5, Paso: 500/600, Perdida: 0.06707\n",
      "Epoca: 5/5, Paso: 600/600, Perdida: 0.03704\n",
      "Precision del modelo en 10000 imagenes: 96.75\n"
     ]
    }
   ],
   "source": [
    "RunModel(\"RN1\", \"Sigm\", \"Adam\", 'runs/RN1_Sigm_Adam', saving_model = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Red Neuronal de una capa escondida + Activaciones ReLU + Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoca: 1/5, Paso: 100/600, Perdida: 0.40839\n",
      "Epoca: 1/5, Paso: 200/600, Perdida: 0.22708\n",
      "Epoca: 1/5, Paso: 300/600, Perdida: 0.34032\n",
      "Epoca: 1/5, Paso: 400/600, Perdida: 0.13182\n",
      "Epoca: 1/5, Paso: 500/600, Perdida: 0.29857\n",
      "Epoca: 1/5, Paso: 600/600, Perdida: 0.13923\n",
      "Epoca: 2/5, Paso: 100/600, Perdida: 0.09076\n",
      "Epoca: 2/5, Paso: 200/600, Perdida: 0.08429\n",
      "Epoca: 2/5, Paso: 300/600, Perdida: 0.04753\n",
      "Epoca: 2/5, Paso: 400/600, Perdida: 0.08848\n",
      "Epoca: 2/5, Paso: 500/600, Perdida: 0.06071\n",
      "Epoca: 2/5, Paso: 600/600, Perdida: 0.09700\n",
      "Epoca: 3/5, Paso: 100/600, Perdida: 0.07444\n",
      "Epoca: 3/5, Paso: 200/600, Perdida: 0.07097\n",
      "Epoca: 3/5, Paso: 300/600, Perdida: 0.09218\n",
      "Epoca: 3/5, Paso: 400/600, Perdida: 0.06149\n",
      "Epoca: 3/5, Paso: 500/600, Perdida: 0.07703\n",
      "Epoca: 3/5, Paso: 600/600, Perdida: 0.07854\n",
      "Epoca: 4/5, Paso: 100/600, Perdida: 0.03885\n",
      "Epoca: 4/5, Paso: 200/600, Perdida: 0.01693\n",
      "Epoca: 4/5, Paso: 300/600, Perdida: 0.04746\n",
      "Epoca: 4/5, Paso: 400/600, Perdida: 0.05456\n",
      "Epoca: 4/5, Paso: 500/600, Perdida: 0.06893\n",
      "Epoca: 4/5, Paso: 600/600, Perdida: 0.05302\n",
      "Epoca: 5/5, Paso: 100/600, Perdida: 0.04532\n",
      "Epoca: 5/5, Paso: 200/600, Perdida: 0.03250\n",
      "Epoca: 5/5, Paso: 300/600, Perdida: 0.03239\n",
      "Epoca: 5/5, Paso: 400/600, Perdida: 0.03191\n",
      "Epoca: 5/5, Paso: 500/600, Perdida: 0.02345\n",
      "Epoca: 5/5, Paso: 600/600, Perdida: 0.03931\n",
      "Precision del modelo en 10000 imagenes: 97.94\n"
     ]
    }
   ],
   "source": [
    "RunModel(\"RN1\", \"ReLU\", \"Adam\", 'runs/RN1_ReLU_Adam', saving_model = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Red Neuronal de 3 capas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Red Neuronal de 3 capas escondidas + Activaciones Sigmoide + SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoca: 1/5, Paso: 100/600, Perdida: 2.30880\n",
      "Epoca: 1/5, Paso: 200/600, Perdida: 2.31254\n",
      "Epoca: 1/5, Paso: 300/600, Perdida: 2.33314\n",
      "Epoca: 1/5, Paso: 400/600, Perdida: 2.29346\n",
      "Epoca: 1/5, Paso: 500/600, Perdida: 2.31503\n",
      "Epoca: 1/5, Paso: 600/600, Perdida: 2.32177\n",
      "Epoca: 2/5, Paso: 100/600, Perdida: 2.30833\n",
      "Epoca: 2/5, Paso: 200/600, Perdida: 2.30469\n",
      "Epoca: 2/5, Paso: 300/600, Perdida: 2.29137\n",
      "Epoca: 2/5, Paso: 400/600, Perdida: 2.31299\n",
      "Epoca: 2/5, Paso: 500/600, Perdida: 2.30627\n",
      "Epoca: 2/5, Paso: 600/600, Perdida: 2.31453\n",
      "Epoca: 3/5, Paso: 100/600, Perdida: 2.28361\n",
      "Epoca: 3/5, Paso: 200/600, Perdida: 2.31213\n",
      "Epoca: 3/5, Paso: 300/600, Perdida: 2.29823\n",
      "Epoca: 3/5, Paso: 400/600, Perdida: 2.30357\n",
      "Epoca: 3/5, Paso: 500/600, Perdida: 2.30616\n",
      "Epoca: 3/5, Paso: 600/600, Perdida: 2.30596\n",
      "Epoca: 4/5, Paso: 100/600, Perdida: 2.30053\n",
      "Epoca: 4/5, Paso: 200/600, Perdida: 2.29734\n",
      "Epoca: 4/5, Paso: 300/600, Perdida: 2.30434\n",
      "Epoca: 4/5, Paso: 400/600, Perdida: 2.30561\n",
      "Epoca: 4/5, Paso: 500/600, Perdida: 2.29731\n",
      "Epoca: 4/5, Paso: 600/600, Perdida: 2.29751\n",
      "Epoca: 5/5, Paso: 100/600, Perdida: 2.30132\n",
      "Epoca: 5/5, Paso: 200/600, Perdida: 2.30346\n",
      "Epoca: 5/5, Paso: 300/600, Perdida: 2.29415\n",
      "Epoca: 5/5, Paso: 400/600, Perdida: 2.30277\n",
      "Epoca: 5/5, Paso: 500/600, Perdida: 2.30229\n",
      "Epoca: 5/5, Paso: 600/600, Perdida: 2.29812\n",
      "Precision del modelo en 10000 imagenes: 11.35\n"
     ]
    }
   ],
   "source": [
    "RunModel(\"RN3\", \"Sigm\", \"SGD\", 'runs/RN3_Sigm_SGD', saving_model = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Red Neuronal de 3 capas escondidas + Activaciones ReLU + SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoca: 1/5, Paso: 100/600, Perdida: 2.30752\n",
      "Epoca: 1/5, Paso: 200/600, Perdida: 2.29760\n",
      "Epoca: 1/5, Paso: 300/600, Perdida: 2.29984\n",
      "Epoca: 1/5, Paso: 400/600, Perdida: 2.30616\n",
      "Epoca: 1/5, Paso: 500/600, Perdida: 2.29596\n",
      "Epoca: 1/5, Paso: 600/600, Perdida: 2.29809\n",
      "Epoca: 2/5, Paso: 100/600, Perdida: 2.29873\n",
      "Epoca: 2/5, Paso: 200/600, Perdida: 2.29051\n",
      "Epoca: 2/5, Paso: 300/600, Perdida: 2.29435\n",
      "Epoca: 2/5, Paso: 400/600, Perdida: 2.28852\n",
      "Epoca: 2/5, Paso: 500/600, Perdida: 2.30028\n",
      "Epoca: 2/5, Paso: 600/600, Perdida: 2.29430\n",
      "Epoca: 3/5, Paso: 100/600, Perdida: 2.28674\n",
      "Epoca: 3/5, Paso: 200/600, Perdida: 2.28457\n",
      "Epoca: 3/5, Paso: 300/600, Perdida: 2.28827\n",
      "Epoca: 3/5, Paso: 400/600, Perdida: 2.29361\n",
      "Epoca: 3/5, Paso: 500/600, Perdida: 2.28675\n",
      "Epoca: 3/5, Paso: 600/600, Perdida: 2.28899\n",
      "Epoca: 4/5, Paso: 100/600, Perdida: 2.29439\n",
      "Epoca: 4/5, Paso: 200/600, Perdida: 2.28527\n",
      "Epoca: 4/5, Paso: 300/600, Perdida: 2.29050\n",
      "Epoca: 4/5, Paso: 400/600, Perdida: 2.27703\n",
      "Epoca: 4/5, Paso: 500/600, Perdida: 2.27671\n",
      "Epoca: 4/5, Paso: 600/600, Perdida: 2.27096\n",
      "Epoca: 5/5, Paso: 100/600, Perdida: 2.27970\n",
      "Epoca: 5/5, Paso: 200/600, Perdida: 2.28153\n",
      "Epoca: 5/5, Paso: 300/600, Perdida: 2.28522\n",
      "Epoca: 5/5, Paso: 400/600, Perdida: 2.27369\n",
      "Epoca: 5/5, Paso: 500/600, Perdida: 2.26710\n",
      "Epoca: 5/5, Paso: 600/600, Perdida: 2.26902\n",
      "Precision del modelo en 10000 imagenes: 35.21\n"
     ]
    }
   ],
   "source": [
    "RunModel(\"RN3\", \"ReLU\", \"SGD\", 'runs/RN3_ReLU_SGD', saving_model = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Red Neuronal de 3 capas escondidas + Activaciones Sigmoide + Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoca: 1/5, Paso: 100/600, Perdida: 1.76503\n",
      "Epoca: 1/5, Paso: 200/600, Perdida: 1.12979\n",
      "Epoca: 1/5, Paso: 300/600, Perdida: 0.88725\n",
      "Epoca: 1/5, Paso: 400/600, Perdida: 0.65549\n",
      "Epoca: 1/5, Paso: 500/600, Perdida: 0.47046\n",
      "Epoca: 1/5, Paso: 600/600, Perdida: 0.40680\n",
      "Epoca: 2/5, Paso: 100/600, Perdida: 0.32816\n",
      "Epoca: 2/5, Paso: 200/600, Perdida: 0.28952\n",
      "Epoca: 2/5, Paso: 300/600, Perdida: 0.23769\n",
      "Epoca: 2/5, Paso: 400/600, Perdida: 0.20549\n",
      "Epoca: 2/5, Paso: 500/600, Perdida: 0.32464\n",
      "Epoca: 2/5, Paso: 600/600, Perdida: 0.20629\n",
      "Epoca: 3/5, Paso: 100/600, Perdida: 0.20500\n",
      "Epoca: 3/5, Paso: 200/600, Perdida: 0.34998\n",
      "Epoca: 3/5, Paso: 300/600, Perdida: 0.12600\n",
      "Epoca: 3/5, Paso: 400/600, Perdida: 0.15098\n",
      "Epoca: 3/5, Paso: 500/600, Perdida: 0.19190\n",
      "Epoca: 3/5, Paso: 600/600, Perdida: 0.04021\n",
      "Epoca: 4/5, Paso: 100/600, Perdida: 0.05183\n",
      "Epoca: 4/5, Paso: 200/600, Perdida: 0.16688\n",
      "Epoca: 4/5, Paso: 300/600, Perdida: 0.07373\n",
      "Epoca: 4/5, Paso: 400/600, Perdida: 0.25256\n",
      "Epoca: 4/5, Paso: 500/600, Perdida: 0.13635\n",
      "Epoca: 4/5, Paso: 600/600, Perdida: 0.09976\n",
      "Epoca: 5/5, Paso: 100/600, Perdida: 0.13871\n",
      "Epoca: 5/5, Paso: 200/600, Perdida: 0.09398\n",
      "Epoca: 5/5, Paso: 300/600, Perdida: 0.06319\n",
      "Epoca: 5/5, Paso: 400/600, Perdida: 0.07715\n",
      "Epoca: 5/5, Paso: 500/600, Perdida: 0.05916\n",
      "Epoca: 5/5, Paso: 600/600, Perdida: 0.12624\n",
      "Precision del modelo en 10000 imagenes: 97.27\n"
     ]
    }
   ],
   "source": [
    "RunModel(\"RN3\", \"Sigm\", \"Adam\", 'runs/RN3_Sigm_Adam', saving_model = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Red Neuronal de 3 capas escondidas + Activaciones ReLU + Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoca: 1/5, Paso: 100/600, Perdida: 0.23658\n",
      "Epoca: 1/5, Paso: 200/600, Perdida: 0.13085\n",
      "Epoca: 1/5, Paso: 300/600, Perdida: 0.21071\n",
      "Epoca: 1/5, Paso: 400/600, Perdida: 0.15012\n",
      "Epoca: 1/5, Paso: 500/600, Perdida: 0.18413\n",
      "Epoca: 1/5, Paso: 600/600, Perdida: 0.08857\n",
      "Epoca: 2/5, Paso: 100/600, Perdida: 0.29261\n",
      "Epoca: 2/5, Paso: 200/600, Perdida: 0.18313\n",
      "Epoca: 2/5, Paso: 300/600, Perdida: 0.12010\n",
      "Epoca: 2/5, Paso: 400/600, Perdida: 0.09019\n",
      "Epoca: 2/5, Paso: 500/600, Perdida: 0.20964\n",
      "Epoca: 2/5, Paso: 600/600, Perdida: 0.08635\n",
      "Epoca: 3/5, Paso: 100/600, Perdida: 0.06402\n",
      "Epoca: 3/5, Paso: 200/600, Perdida: 0.13483\n",
      "Epoca: 3/5, Paso: 300/600, Perdida: 0.07353\n",
      "Epoca: 3/5, Paso: 400/600, Perdida: 0.05996\n",
      "Epoca: 3/5, Paso: 500/600, Perdida: 0.05578\n",
      "Epoca: 3/5, Paso: 600/600, Perdida: 0.09890\n",
      "Epoca: 4/5, Paso: 100/600, Perdida: 0.01791\n",
      "Epoca: 4/5, Paso: 200/600, Perdida: 0.05250\n",
      "Epoca: 4/5, Paso: 300/600, Perdida: 0.04896\n",
      "Epoca: 4/5, Paso: 400/600, Perdida: 0.10034\n",
      "Epoca: 4/5, Paso: 500/600, Perdida: 0.02419\n",
      "Epoca: 4/5, Paso: 600/600, Perdida: 0.10551\n",
      "Epoca: 5/5, Paso: 100/600, Perdida: 0.13595\n",
      "Epoca: 5/5, Paso: 200/600, Perdida: 0.04264\n",
      "Epoca: 5/5, Paso: 300/600, Perdida: 0.04766\n",
      "Epoca: 5/5, Paso: 400/600, Perdida: 0.06977\n",
      "Epoca: 5/5, Paso: 500/600, Perdida: 0.00561\n",
      "Epoca: 5/5, Paso: 600/600, Perdida: 0.03339\n",
      "Precision del modelo en 10000 imagenes: 97.76\n"
     ]
    }
   ],
   "source": [
    "RunModel(\"RN3\", \"ReLU\", \"Adam\", 'runs/RN3_ReLU_Adam', saving_model = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Red Neuronal de 5 capas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Red Neuronal de 5 capas escondidas + Activaciones Sigmoide + SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoca: 1/5, Paso: 100/600, Perdida: 2.34314\n",
      "Epoca: 1/5, Paso: 200/600, Perdida: 2.28729\n",
      "Epoca: 1/5, Paso: 300/600, Perdida: 2.31738\n",
      "Epoca: 1/5, Paso: 400/600, Perdida: 2.33431\n",
      "Epoca: 1/5, Paso: 500/600, Perdida: 2.29466\n",
      "Epoca: 1/5, Paso: 600/600, Perdida: 2.29585\n",
      "Epoca: 2/5, Paso: 100/600, Perdida: 2.31283\n",
      "Epoca: 2/5, Paso: 200/600, Perdida: 2.30929\n",
      "Epoca: 2/5, Paso: 300/600, Perdida: 2.31403\n",
      "Epoca: 2/5, Paso: 400/600, Perdida: 2.28551\n",
      "Epoca: 2/5, Paso: 500/600, Perdida: 2.31438\n",
      "Epoca: 2/5, Paso: 600/600, Perdida: 2.29786\n",
      "Epoca: 3/5, Paso: 100/600, Perdida: 2.29774\n",
      "Epoca: 3/5, Paso: 200/600, Perdida: 2.30407\n",
      "Epoca: 3/5, Paso: 300/600, Perdida: 2.30064\n",
      "Epoca: 3/5, Paso: 400/600, Perdida: 2.30033\n",
      "Epoca: 3/5, Paso: 500/600, Perdida: 2.31409\n",
      "Epoca: 3/5, Paso: 600/600, Perdida: 2.30282\n",
      "Epoca: 4/5, Paso: 100/600, Perdida: 2.30571\n",
      "Epoca: 4/5, Paso: 200/600, Perdida: 2.29104\n",
      "Epoca: 4/5, Paso: 300/600, Perdida: 2.30091\n",
      "Epoca: 4/5, Paso: 400/600, Perdida: 2.29528\n",
      "Epoca: 4/5, Paso: 500/600, Perdida: 2.30531\n",
      "Epoca: 4/5, Paso: 600/600, Perdida: 2.29843\n",
      "Epoca: 5/5, Paso: 100/600, Perdida: 2.30664\n",
      "Epoca: 5/5, Paso: 200/600, Perdida: 2.30174\n",
      "Epoca: 5/5, Paso: 300/600, Perdida: 2.29718\n",
      "Epoca: 5/5, Paso: 400/600, Perdida: 2.30193\n",
      "Epoca: 5/5, Paso: 500/600, Perdida: 2.29760\n",
      "Epoca: 5/5, Paso: 600/600, Perdida: 2.31084\n",
      "Precision del modelo en 10000 imagenes: 11.35\n"
     ]
    }
   ],
   "source": [
    "RunModel(\"RN5\", \"Sigm\", \"SGD\", 'runs/RN5_Sigm_SGD', saving_model = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Red Neuronal de 5 capas escondidas + Activaciones ReLU + SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoca: 1/5, Paso: 100/600, Perdida: 2.29845\n",
      "Epoca: 1/5, Paso: 200/600, Perdida: 2.30885\n",
      "Epoca: 1/5, Paso: 300/600, Perdida: 2.29811\n",
      "Epoca: 1/5, Paso: 400/600, Perdida: 2.31248\n",
      "Epoca: 1/5, Paso: 500/600, Perdida: 2.30376\n",
      "Epoca: 1/5, Paso: 600/600, Perdida: 2.30326\n",
      "Epoca: 2/5, Paso: 100/600, Perdida: 2.30227\n",
      "Epoca: 2/5, Paso: 200/600, Perdida: 2.30039\n",
      "Epoca: 2/5, Paso: 300/600, Perdida: 2.31407\n",
      "Epoca: 2/5, Paso: 400/600, Perdida: 2.30311\n",
      "Epoca: 2/5, Paso: 500/600, Perdida: 2.30233\n",
      "Epoca: 2/5, Paso: 600/600, Perdida: 2.30865\n",
      "Epoca: 3/5, Paso: 100/600, Perdida: 2.30527\n",
      "Epoca: 3/5, Paso: 200/600, Perdida: 2.29979\n",
      "Epoca: 3/5, Paso: 300/600, Perdida: 2.31136\n",
      "Epoca: 3/5, Paso: 400/600, Perdida: 2.30690\n",
      "Epoca: 3/5, Paso: 500/600, Perdida: 2.31134\n",
      "Epoca: 3/5, Paso: 600/600, Perdida: 2.30824\n",
      "Epoca: 4/5, Paso: 100/600, Perdida: 2.30211\n",
      "Epoca: 4/5, Paso: 200/600, Perdida: 2.30509\n",
      "Epoca: 4/5, Paso: 300/600, Perdida: 2.31265\n",
      "Epoca: 4/5, Paso: 400/600, Perdida: 2.30074\n",
      "Epoca: 4/5, Paso: 500/600, Perdida: 2.30944\n",
      "Epoca: 4/5, Paso: 600/600, Perdida: 2.30186\n",
      "Epoca: 5/5, Paso: 100/600, Perdida: 2.29582\n",
      "Epoca: 5/5, Paso: 200/600, Perdida: 2.29964\n",
      "Epoca: 5/5, Paso: 300/600, Perdida: 2.30309\n",
      "Epoca: 5/5, Paso: 400/600, Perdida: 2.29209\n",
      "Epoca: 5/5, Paso: 500/600, Perdida: 2.30024\n",
      "Epoca: 5/5, Paso: 600/600, Perdida: 2.30000\n",
      "Precision del modelo en 10000 imagenes: 11.35\n"
     ]
    }
   ],
   "source": [
    "RunModel(\"RN5\", \"ReLU\", \"SGD\", 'runs/RN5_ReLU_SGD', saving_model = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Red Neuronal de 5 capas escondidas + Activaciones Sigmoide + Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoca: 1/5, Paso: 100/600, Perdida: 1.75372\n",
      "Epoca: 1/5, Paso: 200/600, Perdida: 1.22390\n",
      "Epoca: 1/5, Paso: 300/600, Perdida: 0.86268\n",
      "Epoca: 1/5, Paso: 400/600, Perdida: 0.72304\n",
      "Epoca: 1/5, Paso: 500/600, Perdida: 0.40169\n",
      "Epoca: 1/5, Paso: 600/600, Perdida: 0.43360\n",
      "Epoca: 2/5, Paso: 100/600, Perdida: 0.26429\n",
      "Epoca: 2/5, Paso: 200/600, Perdida: 0.23229\n",
      "Epoca: 2/5, Paso: 300/600, Perdida: 0.30579\n",
      "Epoca: 2/5, Paso: 400/600, Perdida: 0.22136\n",
      "Epoca: 2/5, Paso: 500/600, Perdida: 0.20515\n",
      "Epoca: 2/5, Paso: 600/600, Perdida: 0.08642\n",
      "Epoca: 3/5, Paso: 100/600, Perdida: 0.18626\n",
      "Epoca: 3/5, Paso: 200/600, Perdida: 0.19002\n",
      "Epoca: 3/5, Paso: 300/600, Perdida: 0.22303\n",
      "Epoca: 3/5, Paso: 400/600, Perdida: 0.13499\n",
      "Epoca: 3/5, Paso: 500/600, Perdida: 0.20281\n",
      "Epoca: 3/5, Paso: 600/600, Perdida: 0.26274\n",
      "Epoca: 4/5, Paso: 100/600, Perdida: 0.06373\n",
      "Epoca: 4/5, Paso: 200/600, Perdida: 0.06455\n",
      "Epoca: 4/5, Paso: 300/600, Perdida: 0.11866\n",
      "Epoca: 4/5, Paso: 400/600, Perdida: 0.14202\n",
      "Epoca: 4/5, Paso: 500/600, Perdida: 0.09213\n",
      "Epoca: 4/5, Paso: 600/600, Perdida: 0.10067\n",
      "Epoca: 5/5, Paso: 100/600, Perdida: 0.07346\n",
      "Epoca: 5/5, Paso: 200/600, Perdida: 0.15667\n",
      "Epoca: 5/5, Paso: 300/600, Perdida: 0.05055\n",
      "Epoca: 5/5, Paso: 400/600, Perdida: 0.06640\n",
      "Epoca: 5/5, Paso: 500/600, Perdida: 0.07834\n",
      "Epoca: 5/5, Paso: 600/600, Perdida: 0.16020\n",
      "Precision del modelo en 10000 imagenes: 97.02\n"
     ]
    }
   ],
   "source": [
    "RunModel(\"RN3\", \"Sigm\", \"Adam\", 'runs/RN5_Sigm_Adam', saving_model = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Red Neuronal de 5 capas escondidas + Activaciones ReLU + Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoca: 1/5, Paso: 100/600, Perdida: 0.47554\n",
      "Epoca: 1/5, Paso: 200/600, Perdida: 0.27499\n",
      "Epoca: 1/5, Paso: 300/600, Perdida: 0.21106\n",
      "Epoca: 1/5, Paso: 400/600, Perdida: 0.23222\n",
      "Epoca: 1/5, Paso: 500/600, Perdida: 0.25960\n",
      "Epoca: 1/5, Paso: 600/600, Perdida: 0.18393\n",
      "Epoca: 2/5, Paso: 100/600, Perdida: 0.12968\n",
      "Epoca: 2/5, Paso: 200/600, Perdida: 0.12914\n",
      "Epoca: 2/5, Paso: 300/600, Perdida: 0.17494\n",
      "Epoca: 2/5, Paso: 400/600, Perdida: 0.23223\n",
      "Epoca: 2/5, Paso: 500/600, Perdida: 0.06750\n",
      "Epoca: 2/5, Paso: 600/600, Perdida: 0.07224\n",
      "Epoca: 3/5, Paso: 100/600, Perdida: 0.05423\n",
      "Epoca: 3/5, Paso: 200/600, Perdida: 0.08579\n",
      "Epoca: 3/5, Paso: 300/600, Perdida: 0.05958\n",
      "Epoca: 3/5, Paso: 400/600, Perdida: 0.22338\n",
      "Epoca: 3/5, Paso: 500/600, Perdida: 0.04557\n",
      "Epoca: 3/5, Paso: 600/600, Perdida: 0.05569\n",
      "Epoca: 4/5, Paso: 100/600, Perdida: 0.14058\n",
      "Epoca: 4/5, Paso: 200/600, Perdida: 0.04078\n",
      "Epoca: 4/5, Paso: 300/600, Perdida: 0.10372\n",
      "Epoca: 4/5, Paso: 400/600, Perdida: 0.10707\n",
      "Epoca: 4/5, Paso: 500/600, Perdida: 0.01342\n",
      "Epoca: 4/5, Paso: 600/600, Perdida: 0.03330\n",
      "Epoca: 5/5, Paso: 100/600, Perdida: 0.13912\n",
      "Epoca: 5/5, Paso: 200/600, Perdida: 0.01556\n",
      "Epoca: 5/5, Paso: 300/600, Perdida: 0.04416\n",
      "Epoca: 5/5, Paso: 400/600, Perdida: 0.03991\n",
      "Epoca: 5/5, Paso: 500/600, Perdida: 0.15979\n",
      "Epoca: 5/5, Paso: 600/600, Perdida: 0.00489\n",
      "Precision del modelo en 10000 imagenes: 97.47\n"
     ]
    }
   ],
   "source": [
    "RunModel(\"RN3\", \"ReLU\", \"Adam\", 'runs/RN5_ReLU_Adam', saving_model = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clasificación con MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bruno César Gonzalez\n",
    "150370"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta sección vamos a demostrar el poder de las redes neuronales conPyTorch. Vamos a usar el conjunto de datosMNIST1\n",
    "1. Instaletorchytorchvisionen su computadora.\n",
    "2. Cree una carpeta llamadadatosen su carpeta de trabajomkdir ./datos.\n",
    "3. Lea acerca de la capa lineal de PyTorchhttps://pytorch.org/docs/stable/nn.html#torch.nn.Linear.\n",
    "4. Cree un archivomodelos.pye implemente el siguiente código que implementaregresión logística multinomial.Rellene las líneas[COMENTARIO]para explicar que hace cada segmento de código."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "# ==================\n",
    "# Regresion logistica multinomial\n",
    "# ==================\n",
    "class RegresionMultinomial(nn.Module):\n",
    "  def __init__(self, input_size, num_classes):\n",
    "    super(RegresionMultinomial, self).__init__()\n",
    "    self.linear = nn.Linear(input_size, num_classes)\n",
    "    \n",
    "  def forward(self, x):\n",
    "    out = self.linear(x)\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Puede probar el modelo RegresionMultinomialcon el siguiente código. Rellene las líneas de [COMENTARIO]para explicar las diferentes secciones del código."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torchvision.datasets import MNIST\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import ToTensor\n",
    "from modelos import RegresionMultinomial\n",
    "\n",
    "# Se verifica si esta disponible CUDA,en caso contraro se usa el procesador\n",
    "device = torch.device('cuda'if torch.cuda.is_available() else'cpu')\n",
    "\n",
    "# Hiper-parametros\n",
    "input_size = 784 # Dimension de datos de entrada (28 x 28)\n",
    "num_classes = 10 # MNIST tiene 10 clases (numeros del 1 al 10)\n",
    "num_epochs = 5 # Numero de epocas para entrenar\n",
    "bs = 100 # Tamano de lote (batch_size)\n",
    "lr = 0.001 # Tasa de aprendizaje\n",
    "\n",
    "# Se bajan los datos MINST\n",
    "\n",
    "root ='./datos'# Carpeta donde se guardaran los datos\n",
    "train_data = MNIST(root, train=True, transform=ToTensor(), download=True)\n",
    "test_data  = MNIST(root, train=False, transform=ToTensor())\n",
    "\n",
    "# Se crea el iterable sobre el dataset\n",
    "train_loader = DataLoader(train_data, batch_size=bs, shuffle=True)\n",
    "test_loader  = DataLoader(test_data,  batch_size=bs, shuffle=False)\n",
    "\n",
    "    \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoca: 1/5, Paso: 100/600, Perdida: 2.20932\n",
      "Epoca: 1/5, Paso: 200/600, Perdida: 2.08961\n",
      "Epoca: 1/5, Paso: 300/600, Perdida: 1.98549\n",
      "Epoca: 1/5, Paso: 400/600, Perdida: 1.91389\n",
      "Epoca: 1/5, Paso: 500/600, Perdida: 1.79837\n",
      "Epoca: 1/5, Paso: 600/600, Perdida: 1.82871\n",
      "Epoca: 2/5, Paso: 100/600, Perdida: 1.71765\n",
      "Epoca: 2/5, Paso: 200/600, Perdida: 1.72486\n",
      "Epoca: 2/5, Paso: 300/600, Perdida: 1.53878\n",
      "Epoca: 2/5, Paso: 400/600, Perdida: 1.54001\n",
      "Epoca: 2/5, Paso: 500/600, Perdida: 1.54258\n",
      "Epoca: 2/5, Paso: 600/600, Perdida: 1.41859\n",
      "Epoca: 3/5, Paso: 100/600, Perdida: 1.45936\n",
      "Epoca: 3/5, Paso: 200/600, Perdida: 1.39035\n",
      "Epoca: 3/5, Paso: 300/600, Perdida: 1.33599\n",
      "Epoca: 3/5, Paso: 400/600, Perdida: 1.25948\n",
      "Epoca: 3/5, Paso: 500/600, Perdida: 1.33553\n",
      "Epoca: 3/5, Paso: 600/600, Perdida: 1.19627\n",
      "Epoca: 4/5, Paso: 100/600, Perdida: 1.16898\n",
      "Epoca: 4/5, Paso: 200/600, Perdida: 1.12092\n",
      "Epoca: 4/5, Paso: 300/600, Perdida: 1.10155\n",
      "Epoca: 4/5, Paso: 400/600, Perdida: 1.08721\n",
      "Epoca: 4/5, Paso: 500/600, Perdida: 1.06619\n",
      "Epoca: 4/5, Paso: 600/600, Perdida: 1.01416\n",
      "Epoca: 5/5, Paso: 100/600, Perdida: 1.13610\n",
      "Epoca: 5/5, Paso: 200/600, Perdida: 1.14016\n",
      "Epoca: 5/5, Paso: 300/600, Perdida: 1.01884\n",
      "Epoca: 5/5, Paso: 400/600, Perdida: 1.13562\n",
      "Epoca: 5/5, Paso: 500/600, Perdida: 0.96281\n",
      "Epoca: 5/5, Paso: 600/600, Perdida: 0.98885\n"
     ]
    }
   ],
   "source": [
    "# ==================\n",
    "# Definimos modelo\n",
    "# ==================\n",
    "\n",
    "# Se define el modelo \n",
    "model = RegresionMultinomial(input_size, num_classes).to(device)\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "\n",
    "# ==================\n",
    "# Optimizacion\n",
    "# ==================\n",
    "\n",
    "# Implementa el gradiente descendiente para la optimizacion\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "\n",
    "# Entrenamiento del modelo\n",
    "for epoch in range(num_epochs):\n",
    "  for i, (xi, yi) in enumerate(train_loader):\n",
    "    \n",
    "    # Las entradas de la imagen se convierten en vectores\n",
    "    xi = xi.reshape(-1, 28*28).to(device)# imagenes\n",
    "    yi = yi.to(device)# etiquetas\n",
    "    \n",
    "    # Propagacion para adelante\n",
    "    output = model(xi)\n",
    "    loss = loss_function(output, yi)\n",
    "    # Propagcion para atras y paso de optimizacion\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if (i+1) % 100 == 0:\n",
    "      print ('Epoca: {}/{}, Paso: {}/{}, Perdida: {:.5f}'.format(epoch+1,num_epochs, i+1, len(train_loader), loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision del modelo en 10000 imagenes: 82.99\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "  correct = 0\n",
    "  total = 0\n",
    "  for xi, yi in test_loader:\n",
    "    # Las entradas de la imagen se convierten en vectores\n",
    "    xi = xi.reshape(-1, 28*28).to(device)\n",
    "    yi = yi.to(device)\n",
    "    \n",
    "    # Se hacen las predicciones\n",
    "    output = model(xi)\n",
    "    _, predicted = torch.max(output.data, 1)\n",
    "    \n",
    "    total += yi.size(0)\n",
    "    correct += (predicted == yi).sum().item()\n",
    "    \n",
    "  print(f'Precision del modelo en {total} imagenes: {100 * correct / total}')\n",
    "\n",
    "des = []\n",
    "des.append(100 * correct / total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Incluya en su archivomodelos.pyla siguiente clase que implementa una red neuronal conuna capa escondidayactivaciones sigmoide. Rellene los comentarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NNh1_sigm(nn.Module):\n",
    "  def __init__(self, input_size, num_classes):\n",
    "\n",
    "    super(NNh1_sigm, self).__init__()\n",
    "\n",
    "    # [COMENTARIO]\n",
    "    hidden_size = 500\n",
    "\n",
    "    # [COMENTARIO]\n",
    "    self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "    self.sigmoid = nn.Sigmoid()\n",
    "    self.fc2 = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "  def forward(self, x):\n",
    "    out = self.fc1(x)\n",
    "    out = self.sigmoid(out)\n",
    "    out = self.fc2(out)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Pruebe el desempeño deRedNeuronaly compare los resultados conRegresionMultinomial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoca: 1/5, Paso: 100/600, Perdida: 2.31203\n",
      "Epoca: 1/5, Paso: 200/600, Perdida: 2.29133\n",
      "Epoca: 1/5, Paso: 300/600, Perdida: 2.29622\n",
      "Epoca: 1/5, Paso: 400/600, Perdida: 2.26429\n",
      "Epoca: 1/5, Paso: 500/600, Perdida: 2.29051\n",
      "Epoca: 1/5, Paso: 600/600, Perdida: 2.29245\n",
      "Epoca: 2/5, Paso: 100/600, Perdida: 2.27338\n",
      "Epoca: 2/5, Paso: 200/600, Perdida: 2.27621\n",
      "Epoca: 2/5, Paso: 300/600, Perdida: 2.26927\n",
      "Epoca: 2/5, Paso: 400/600, Perdida: 2.26046\n",
      "Epoca: 2/5, Paso: 500/600, Perdida: 2.26747\n",
      "Epoca: 2/5, Paso: 600/600, Perdida: 2.25818\n",
      "Epoca: 3/5, Paso: 100/600, Perdida: 2.26721\n",
      "Epoca: 3/5, Paso: 200/600, Perdida: 2.25145\n",
      "Epoca: 3/5, Paso: 300/600, Perdida: 2.24696\n",
      "Epoca: 3/5, Paso: 400/600, Perdida: 2.24338\n",
      "Epoca: 3/5, Paso: 500/600, Perdida: 2.24142\n",
      "Epoca: 3/5, Paso: 600/600, Perdida: 2.24352\n",
      "Epoca: 4/5, Paso: 100/600, Perdida: 2.24736\n",
      "Epoca: 4/5, Paso: 200/600, Perdida: 2.21941\n",
      "Epoca: 4/5, Paso: 300/600, Perdida: 2.22734\n",
      "Epoca: 4/5, Paso: 400/600, Perdida: 2.20880\n",
      "Epoca: 4/5, Paso: 500/600, Perdida: 2.21717\n",
      "Epoca: 4/5, Paso: 600/600, Perdida: 2.22543\n",
      "Epoca: 5/5, Paso: 100/600, Perdida: 2.20325\n",
      "Epoca: 5/5, Paso: 200/600, Perdida: 2.21029\n",
      "Epoca: 5/5, Paso: 300/600, Perdida: 2.20404\n",
      "Epoca: 5/5, Paso: 400/600, Perdida: 2.19139\n",
      "Epoca: 5/5, Paso: 500/600, Perdida: 2.18950\n",
      "Epoca: 5/5, Paso: 600/600, Perdida: 2.19521\n"
     ]
    }
   ],
   "source": [
    "# Se define el modelo \n",
    "model2 = NNh1_sigm(input_size, num_classes).to(device)\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "\n",
    "# ==================\n",
    "# Optimizacion\n",
    "# ==================\n",
    "\n",
    "optimizer = torch.optim.SGD(model2.parameters(), lr=lr)\n",
    "\n",
    "# Entrenamiento del modelo\n",
    "for epoch in range(num_epochs):\n",
    "  for i, (xi, yi) in enumerate(train_loader):\n",
    "    \n",
    "    xi = xi.reshape(-1, 28*28).to(device)# imagenes\n",
    "    yi = yi.to(device)# etiquetas\n",
    "    \n",
    "    # Propagacion para adelante\n",
    "    output = model2(xi)\n",
    "    loss = loss_function(output, yi)\n",
    "    # Propagcion para atras y paso de optimizacion\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if (i+1) % 100 == 0:\n",
    "      print ('Epoca: {}/{}, Paso: {}/{}, Perdida: {:.5f}'.format(epoch+1,num_epochs, i+1, len(train_loader), loss.item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probamos el desempeño del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision del modelo en 10000 imagenes: 47.85\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "  correct = 0\n",
    "  total = 0\n",
    "  for xi, yi in test_loader:\n",
    "    # [COMENTARIO]\n",
    "    xi = xi.reshape(-1, 28*28).to(device)\n",
    "    yi = yi.to(device)\n",
    "    \n",
    "    # [COMENTARIO]\n",
    "    output = model2(xi)\n",
    "    _, predicted = torch.max(output.data, 1)\n",
    "    \n",
    "    total += yi.size(0)\n",
    "    correct += (predicted == yi).sum().item()\n",
    "    \n",
    "  print(f'Precision del modelo en {total} imagenes: {100 * correct / total}')\n",
    "des.append(100 * correct / total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El desempeño es mucho peor que el que no tiene capa oculta."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Considere las siguientes arquitecturas de redes neuronales:\n",
    "\n",
    "a)RedNeuronal: Una capa escondida con 500 unidades (la que ya tenemos).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b)RedNeuronal3: Tres capas escondidas de 500, 100 y 30 unidades.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero definimos el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NNh3_sigm(nn.Module):\n",
    "  def __init__(self, input_size, num_classes):\n",
    "\n",
    "    super(NNh3_sigm, self).__init__()\n",
    "\n",
    "    hidden_size1 = 500\n",
    "    hidden_size2 = 100\n",
    "    hidden_size3 = 30\n",
    "\n",
    "    self.fc1 = nn.Linear(input_size, hidden_size1)\n",
    "    self.fc2 = nn.Linear(hidden_size1, hidden_size2)\n",
    "    self.fc3 = nn.Linear(hidden_size2, hidden_size3)\n",
    "    self.fc4 = nn.Linear(hidden_size3, num_classes)\n",
    "    self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "  def forward(self, x):\n",
    "    out = self.sigmoid(self.fc1(x))\n",
    "    out = self.sigmoid(self.fc2(out))\n",
    "    out = self.sigmoid(self.fc3(out))\n",
    "    out = self.sigmoid(self.fc4(out))\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora entrenamos el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoca: 1/5, Paso: 100/600, Perdida: 2.30550\n",
      "Epoca: 1/5, Paso: 200/600, Perdida: 2.30998\n",
      "Epoca: 1/5, Paso: 300/600, Perdida: 2.29934\n",
      "Epoca: 1/5, Paso: 400/600, Perdida: 2.30140\n",
      "Epoca: 1/5, Paso: 500/600, Perdida: 2.30942\n",
      "Epoca: 1/5, Paso: 600/600, Perdida: 2.29960\n",
      "Epoca: 2/5, Paso: 100/600, Perdida: 2.30305\n",
      "Epoca: 2/5, Paso: 200/600, Perdida: 2.29799\n",
      "Epoca: 2/5, Paso: 300/600, Perdida: 2.30103\n",
      "Epoca: 2/5, Paso: 400/600, Perdida: 2.30892\n",
      "Epoca: 2/5, Paso: 500/600, Perdida: 2.31090\n",
      "Epoca: 2/5, Paso: 600/600, Perdida: 2.30416\n",
      "Epoca: 3/5, Paso: 100/600, Perdida: 2.30391\n",
      "Epoca: 3/5, Paso: 200/600, Perdida: 2.31957\n",
      "Epoca: 3/5, Paso: 300/600, Perdida: 2.30917\n",
      "Epoca: 3/5, Paso: 400/600, Perdida: 2.30333\n",
      "Epoca: 3/5, Paso: 500/600, Perdida: 2.30456\n",
      "Epoca: 3/5, Paso: 600/600, Perdida: 2.30953\n",
      "Epoca: 4/5, Paso: 100/600, Perdida: 2.30875\n",
      "Epoca: 4/5, Paso: 200/600, Perdida: 2.29871\n",
      "Epoca: 4/5, Paso: 300/600, Perdida: 2.30315\n",
      "Epoca: 4/5, Paso: 400/600, Perdida: 2.28979\n",
      "Epoca: 4/5, Paso: 500/600, Perdida: 2.30842\n",
      "Epoca: 4/5, Paso: 600/600, Perdida: 2.29938\n",
      "Epoca: 5/5, Paso: 100/600, Perdida: 2.30531\n",
      "Epoca: 5/5, Paso: 200/600, Perdida: 2.30320\n",
      "Epoca: 5/5, Paso: 300/600, Perdida: 2.29954\n",
      "Epoca: 5/5, Paso: 400/600, Perdida: 2.30225\n",
      "Epoca: 5/5, Paso: 500/600, Perdida: 2.31184\n",
      "Epoca: 5/5, Paso: 600/600, Perdida: 2.30473\n"
     ]
    }
   ],
   "source": [
    "# Se define el modelo \n",
    "model3 = NNh3_sigm(input_size, num_classes).to(device)\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "\n",
    "# ==================\n",
    "# Optimizacion\n",
    "# ==================\n",
    "\n",
    "optimizer = torch.optim.SGD(model3.parameters(), lr=lr)\n",
    "\n",
    "# Entrenamiento del modelo\n",
    "for epoch in range(num_epochs):\n",
    "  for i, (xi, yi) in enumerate(train_loader):\n",
    "    \n",
    "    xi = xi.reshape(-1, 28*28).to(device)# imagenes\n",
    "    yi = yi.to(device)# etiquetas\n",
    "    \n",
    "    # Propagacion para adelante\n",
    "    output = model3(xi)\n",
    "    loss = loss_function(output, yi)\n",
    "    # Propagcion para atras y paso de optimizacion\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if (i+1) % 100 == 0:\n",
    "      print ('Epoca: {}/{}, Paso: {}/{}, Perdida: {:.5f}'.format(epoch+1,num_epochs, i+1, len(train_loader), loss.item()))\n",
    "      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision del modelo en 10000 imagenes: 10.32\n"
     ]
    }
   ],
   "source": [
    "# Prueba del modelo\n",
    "# Al probar, usamos torch.no_grad() porque [COMENTARIO]\n",
    "with torch.no_grad():\n",
    "  correct = 0\n",
    "  total = 0\n",
    "  for xi, yi in test_loader:\n",
    "    # [COMENTARIO]\n",
    "    xi = xi.reshape(-1, 28*28).to(device)\n",
    "    yi = yi.to(device)\n",
    "    \n",
    "    # [COMENTARIO]\n",
    "    output = model3(xi)\n",
    "    _, predicted = torch.max(output.data, 1)\n",
    "    \n",
    "    total += yi.size(0)\n",
    "    correct += (predicted == yi).sum().item()\n",
    "    \n",
    "  print(f'Precision del modelo en {total} imagenes: {100 * correct / total}')\n",
    "des.append(100 * correct / total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c)RedNeuronal5: Cinco capas escondidas de 500, 300, 100, 50, 30 unidades.Experimente cómo cambia el desempeño en cada uno de estos modelos al variar las funciones de activación y eloptimizador. Al hacer esto:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NNh5_sigm(nn.Module):\n",
    "  def __init__(self, input_size, num_classes):\n",
    "\n",
    "    super(NNh5_sigm, self).__init__()\n",
    "\n",
    "    hidden_size1 = 500\n",
    "    hidden_size2 = 300\n",
    "    hidden_size3 = 100\n",
    "    hidden_size4 = 50\n",
    "    hidden_size5 = 30\n",
    "\n",
    "    self.fc1 = nn.Linear(input_size, hidden_size1)\n",
    "    self.fc2 = nn.Linear(hidden_size1, hidden_size2)\n",
    "    self.fc3 = nn.Linear(hidden_size2, hidden_size3)\n",
    "    self.fc4 = nn.Linear(hidden_size3, hidden_size4)\n",
    "    self.fc5 = nn.Linear(hidden_size4, hidden_size5)\n",
    "    self.fc6 = nn.Linear(hidden_size5, num_classes)\n",
    "    self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "  def forward(self, x):\n",
    "    out = self.sigmoid(self.fc1(x))\n",
    "    out = self.sigmoid(self.fc2(out))\n",
    "    out = self.sigmoid(self.fc3(out))\n",
    "    out = self.sigmoid(self.fc4(out))\n",
    "    out = self.sigmoid(self.fc5(out))\n",
    "    out = self.sigmoid(self.fc6(out))\n",
    "    return out\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoca: 1/5, Paso: 100/600, Perdida: 2.30082\n",
      "Epoca: 1/5, Paso: 200/600, Perdida: 2.30114\n",
      "Epoca: 1/5, Paso: 300/600, Perdida: 2.31952\n",
      "Epoca: 1/5, Paso: 400/600, Perdida: 2.29803\n",
      "Epoca: 1/5, Paso: 500/600, Perdida: 2.30280\n",
      "Epoca: 1/5, Paso: 600/600, Perdida: 2.30707\n",
      "Epoca: 2/5, Paso: 100/600, Perdida: 2.30654\n",
      "Epoca: 2/5, Paso: 200/600, Perdida: 2.30333\n",
      "Epoca: 2/5, Paso: 300/600, Perdida: 2.30372\n",
      "Epoca: 2/5, Paso: 400/600, Perdida: 2.31257\n",
      "Epoca: 2/5, Paso: 500/600, Perdida: 2.31748\n",
      "Epoca: 2/5, Paso: 600/600, Perdida: 2.30962\n",
      "Epoca: 3/5, Paso: 100/600, Perdida: 2.28999\n",
      "Epoca: 3/5, Paso: 200/600, Perdida: 2.30612\n",
      "Epoca: 3/5, Paso: 300/600, Perdida: 2.30869\n",
      "Epoca: 3/5, Paso: 400/600, Perdida: 2.31377\n",
      "Epoca: 3/5, Paso: 500/600, Perdida: 2.30172\n",
      "Epoca: 3/5, Paso: 600/600, Perdida: 2.32078\n",
      "Epoca: 4/5, Paso: 100/600, Perdida: 2.30664\n",
      "Epoca: 4/5, Paso: 200/600, Perdida: 2.30103\n",
      "Epoca: 4/5, Paso: 300/600, Perdida: 2.30953\n",
      "Epoca: 4/5, Paso: 400/600, Perdida: 2.31692\n",
      "Epoca: 4/5, Paso: 500/600, Perdida: 2.29758\n",
      "Epoca: 4/5, Paso: 600/600, Perdida: 2.31104\n",
      "Epoca: 5/5, Paso: 100/600, Perdida: 2.30177\n",
      "Epoca: 5/5, Paso: 200/600, Perdida: 2.30352\n",
      "Epoca: 5/5, Paso: 300/600, Perdida: 2.30723\n",
      "Epoca: 5/5, Paso: 400/600, Perdida: 2.30299\n",
      "Epoca: 5/5, Paso: 500/600, Perdida: 2.30443\n",
      "Epoca: 5/5, Paso: 600/600, Perdida: 2.31527\n"
     ]
    }
   ],
   "source": [
    "model4 = NNh5_sigm(input_size, num_classes).to(device)\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "\n",
    "# ==================\n",
    "# Optimizacion\n",
    "# ==================\n",
    "\n",
    "# [COMENTARIO]\n",
    "optimizer = torch.optim.SGD(model4.parameters(), lr=lr)\n",
    "\n",
    "# Entrenamiento del modelo\n",
    "for epoch in range(num_epochs):\n",
    "  for i, (xi, yi) in enumerate(train_loader):\n",
    "    \n",
    "    # [COMENTARIO]\n",
    "    xi = xi.reshape(-1, 28*28).to(device)# imagenes\n",
    "    yi = yi.to(device)# etiquetas\n",
    "    \n",
    "    # Propagacion para adelante\n",
    "    output = model4(xi)\n",
    "    loss = loss_function(output, yi)\n",
    "    # Propagcion para atras y paso de optimizacion\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if (i+1) % 100 == 0:\n",
    "      print ('Epoca: {}/{}, Paso: {}/{}, Perdida: {:.5f}'.format(epoch+1,num_epochs, i+1, len(train_loader), loss.item()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision del modelo en 10000 imagenes: 9.8\n"
     ]
    }
   ],
   "source": [
    "# Prueba del modelo\n",
    "with torch.no_grad():\n",
    "  correct = 0\n",
    "  total = 0\n",
    "  for xi, yi in test_loader:\n",
    "    # [COMENTARIO]\n",
    "    xi = xi.reshape(-1, 28*28).to(device)\n",
    "    yi = yi.to(device)\n",
    "    \n",
    "    # [COMENTARIO]\n",
    "    output = model4(xi)\n",
    "    _, predicted = torch.max(output.data, 1)\n",
    "    \n",
    "    total += yi.size(0)\n",
    "    correct += (predicted == yi).sum().item()\n",
    "    \n",
    "  print(f'Precision del modelo en {total} imagenes: {100 * correct / total}')\n",
    "des.append(100 * correct / total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experimente cómo cambia el desempeño en cada uno de estos modelos al variar las funciones de activación y el\n",
    "optimizador."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero definamos la red on una capa escondida *ReLu*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NNh1_relu(nn.Module):\n",
    "  def __init__(self, input_size, num_classes):\n",
    "\n",
    "    super(NNh1_relu, self).__init__()\n",
    "\n",
    "    hidden_size = 500\n",
    "\n",
    "    self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "    self.relu = nn.ReLU()\n",
    "    self.fc2 = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "  def forward(self, x):\n",
    "    out = self.fc1(x)\n",
    "    out = self.relu(out)\n",
    "    out = self.fc2(out)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora entrenemos el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoca: 1/5, Paso: 100/600, Perdida: 2.27688\n",
      "Epoca: 1/5, Paso: 200/600, Perdida: 2.25788\n",
      "Epoca: 1/5, Paso: 300/600, Perdida: 2.24187\n",
      "Epoca: 1/5, Paso: 400/600, Perdida: 2.21653\n",
      "Epoca: 1/5, Paso: 500/600, Perdida: 2.19121\n",
      "Epoca: 1/5, Paso: 600/600, Perdida: 2.18727\n",
      "Epoca: 2/5, Paso: 100/600, Perdida: 2.14241\n",
      "Epoca: 2/5, Paso: 200/600, Perdida: 2.13404\n",
      "Epoca: 2/5, Paso: 300/600, Perdida: 2.09911\n",
      "Epoca: 2/5, Paso: 400/600, Perdida: 2.06877\n",
      "Epoca: 2/5, Paso: 500/600, Perdida: 2.07198\n",
      "Epoca: 2/5, Paso: 600/600, Perdida: 2.00438\n",
      "Epoca: 3/5, Paso: 100/600, Perdida: 1.96570\n",
      "Epoca: 3/5, Paso: 200/600, Perdida: 1.94888\n",
      "Epoca: 3/5, Paso: 300/600, Perdida: 1.90564\n",
      "Epoca: 3/5, Paso: 400/600, Perdida: 1.89386\n",
      "Epoca: 3/5, Paso: 500/600, Perdida: 1.85003\n",
      "Epoca: 3/5, Paso: 600/600, Perdida: 1.81501\n",
      "Epoca: 4/5, Paso: 100/600, Perdida: 1.74580\n",
      "Epoca: 4/5, Paso: 200/600, Perdida: 1.72433\n",
      "Epoca: 4/5, Paso: 300/600, Perdida: 1.78170\n",
      "Epoca: 4/5, Paso: 400/600, Perdida: 1.62418\n",
      "Epoca: 4/5, Paso: 500/600, Perdida: 1.67674\n",
      "Epoca: 4/5, Paso: 600/600, Perdida: 1.62160\n",
      "Epoca: 5/5, Paso: 100/600, Perdida: 1.60137\n",
      "Epoca: 5/5, Paso: 200/600, Perdida: 1.50576\n",
      "Epoca: 5/5, Paso: 300/600, Perdida: 1.56279\n",
      "Epoca: 5/5, Paso: 400/600, Perdida: 1.47336\n",
      "Epoca: 5/5, Paso: 500/600, Perdida: 1.48461\n",
      "Epoca: 5/5, Paso: 600/600, Perdida: 1.38327\n"
     ]
    }
   ],
   "source": [
    "model5 = NNh1_relu(input_size, num_classes).to(device)\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = torch.optim.SGD(model5.parameters(), lr=lr)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "  for i, (xi, yi) in enumerate(train_loader):\n",
    "    \n",
    "    xi = xi.reshape(-1, 28*28).to(device)# imagenes\n",
    "    yi = yi.to(device)# etiquetas\n",
    "    \n",
    "    # Propagacion para adelante\n",
    "    output = model5(xi)\n",
    "    loss = loss_function(output, yi)\n",
    "    # Propagcion para atras y paso de optimizacion\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if (i+1) % 100 == 0:\n",
    "      print ('Epoca: {}/{}, Paso: {}/{}, Perdida: {:.5f}'.format(epoch+1,num_epochs, i+1, len(train_loader), loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision del modelo en 10000 imagenes: 78.87\n"
     ]
    }
   ],
   "source": [
    "# Prueba del modelo\n",
    "with torch.no_grad():\n",
    "  correct = 0\n",
    "  total = 0\n",
    "  for xi, yi in test_loader:\n",
    "    # [COMENTARIO]\n",
    "    xi = xi.reshape(-1, 28*28).to(device)\n",
    "    yi = yi.to(device)\n",
    "    \n",
    "    # [COMENTARIO]\n",
    "    output = model5(xi)\n",
    "    _, predicted = torch.max(output.data, 1)\n",
    "    \n",
    "    total += yi.size(0)\n",
    "    correct += (predicted == yi).sum().item()\n",
    "    \n",
    "  print(f'Precision del modelo en {total} imagenes: {100 * correct / total}')\n",
    "des.append(100 * correct / total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora definamos el modelo Relu con 3 capas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NNh3_relu(nn.Module):\n",
    "  def __init__(self, input_size, num_classes):\n",
    "\n",
    "    super(NNh3_relu, self).__init__()\n",
    "\n",
    "    hidden_size1 = 500\n",
    "    hidden_size2 = 100\n",
    "    hidden_size3 = 30\n",
    "\n",
    "    self.fc1 = nn.Linear(input_size, hidden_size1)\n",
    "    self.fc2 = nn.Linear(hidden_size1, hidden_size2)\n",
    "    self.fc3 = nn.Linear(hidden_size2, hidden_size3)\n",
    "    self.fc4 = nn.Linear(hidden_size3, num_classes)\n",
    "    self.relu = nn.ReLU()\n",
    "\n",
    "  def forward(self, x):\n",
    "    out = self.relu(self.fc1(x))\n",
    "    out = self.relu(self.fc2(out))\n",
    "    out = self.relu(self.fc3(out))\n",
    "    out = self.relu(self.fc4(out))\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrenando el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoca: 1/5, Paso: 100/600, Perdida: 2.27627\n",
      "Epoca: 1/5, Paso: 200/600, Perdida: 2.24886\n",
      "Epoca: 1/5, Paso: 300/600, Perdida: 2.23952\n",
      "Epoca: 1/5, Paso: 400/600, Perdida: 2.21438\n",
      "Epoca: 1/5, Paso: 500/600, Perdida: 2.17392\n",
      "Epoca: 1/5, Paso: 600/600, Perdida: 2.15611\n",
      "Epoca: 2/5, Paso: 100/600, Perdida: 2.13888\n",
      "Epoca: 2/5, Paso: 200/600, Perdida: 2.10315\n",
      "Epoca: 2/5, Paso: 300/600, Perdida: 2.10900\n",
      "Epoca: 2/5, Paso: 400/600, Perdida: 2.04991\n",
      "Epoca: 2/5, Paso: 500/600, Perdida: 1.99730\n",
      "Epoca: 2/5, Paso: 600/600, Perdida: 1.98222\n",
      "Epoca: 3/5, Paso: 100/600, Perdida: 1.98620\n",
      "Epoca: 3/5, Paso: 200/600, Perdida: 1.94729\n",
      "Epoca: 3/5, Paso: 300/600, Perdida: 1.88226\n",
      "Epoca: 3/5, Paso: 400/600, Perdida: 1.90294\n",
      "Epoca: 3/5, Paso: 500/600, Perdida: 1.85093\n",
      "Epoca: 3/5, Paso: 600/600, Perdida: 1.76596\n",
      "Epoca: 4/5, Paso: 100/600, Perdida: 1.73971\n",
      "Epoca: 4/5, Paso: 200/600, Perdida: 1.76559\n",
      "Epoca: 4/5, Paso: 300/600, Perdida: 1.72703\n",
      "Epoca: 4/5, Paso: 400/600, Perdida: 1.65808\n",
      "Epoca: 4/5, Paso: 500/600, Perdida: 1.63011\n",
      "Epoca: 4/5, Paso: 600/600, Perdida: 1.57422\n",
      "Epoca: 5/5, Paso: 100/600, Perdida: 1.54173\n",
      "Epoca: 5/5, Paso: 200/600, Perdida: 1.50620\n",
      "Epoca: 5/5, Paso: 300/600, Perdida: 1.53278\n",
      "Epoca: 5/5, Paso: 400/600, Perdida: 1.42299\n",
      "Epoca: 5/5, Paso: 500/600, Perdida: 1.48544\n",
      "Epoca: 5/5, Paso: 600/600, Perdida: 1.37373\n"
     ]
    }
   ],
   "source": [
    "model6 = NNh1_relu(input_size, num_classes).to(device)\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = torch.optim.SGD(model6.parameters(), lr=lr)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "  for i, (xi, yi) in enumerate(train_loader):\n",
    "    \n",
    "    xi = xi.reshape(-1, 28*28).to(device)# imagenes\n",
    "    yi = yi.to(device)# etiquetas\n",
    "    \n",
    "    # Propagacion para adelante\n",
    "    output = model6(xi)\n",
    "    loss = loss_function(output, yi)\n",
    "    # Propagcion para atras y paso de optimizacion\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if (i+1) % 100 == 0:\n",
    "      print ('Epoca: {}/{}, Paso: {}/{}, Perdida: {:.5f}'.format(epoch+1,num_epochs, i+1, len(train_loader), loss.item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora probamos el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision del modelo en 10000 imagenes: 77.61\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "  correct = 0\n",
    "  total = 0\n",
    "  for xi, yi in test_loader:\n",
    "\n",
    "    xi = xi.reshape(-1, 28*28).to(device)\n",
    "    yi = yi.to(device)\n",
    "    \n",
    "    output = model6(xi)\n",
    "    _, predicted = torch.max(output.data, 1)\n",
    "    \n",
    "    total += yi.size(0)\n",
    "    correct += (predicted == yi).sum().item()\n",
    "    \n",
    "  print(f'Precision del modelo en {total} imagenes: {100 * correct / total}')\n",
    "des.append(100 * correct / total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por último hacemos el modela con 5 capas Relu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NNh5_relu(nn.Module):\n",
    "  def __init__(self, input_size, num_classes):\n",
    "\n",
    "    super(NNh5_relu, self).__init__()\n",
    "\n",
    "    hidden_size1 = 500\n",
    "    hidden_size2 = 300\n",
    "    hidden_size3 = 100\n",
    "    hidden_size4 = 50\n",
    "    hidden_size5 = 30\n",
    "\n",
    "    self.fc1 = nn.Linear(input_size, hidden_size1)\n",
    "    self.fc2 = nn.Linear(hidden_size1, hidden_size2)\n",
    "    self.fc3 = nn.Linear(hidden_size2, hidden_size3)\n",
    "    self.fc4 = nn.Linear(hidden_size3, hidden_size4)\n",
    "    self.fc5 = nn.Linear(hidden_size4, hidden_size5)\n",
    "    self.fc6 = nn.Linear(hidden_size5, num_classes)\n",
    "    self.relu = nn.ReLU()\n",
    "\n",
    "  def forward(self, x):\n",
    "    out = self.relu(self.fc1(x))\n",
    "    out = self.relu(self.fc2(out))\n",
    "    out = self.relu(self.fc3(out))\n",
    "    out = self.relu(self.fc4(out))\n",
    "    out = self.relu(self.fc5(out))\n",
    "    out = self.relu(self.fc6(out))\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoca: 1/5, Paso: 100/600, Perdida: 2.27134\n",
      "Epoca: 1/5, Paso: 200/600, Perdida: 2.23667\n",
      "Epoca: 1/5, Paso: 300/600, Perdida: 2.21992\n",
      "Epoca: 1/5, Paso: 400/600, Perdida: 2.18641\n",
      "Epoca: 1/5, Paso: 500/600, Perdida: 2.18784\n",
      "Epoca: 1/5, Paso: 600/600, Perdida: 2.15874\n",
      "Epoca: 2/5, Paso: 100/600, Perdida: 2.10500\n",
      "Epoca: 2/5, Paso: 200/600, Perdida: 2.08809\n",
      "Epoca: 2/5, Paso: 300/600, Perdida: 2.07441\n",
      "Epoca: 2/5, Paso: 400/600, Perdida: 2.04522\n",
      "Epoca: 2/5, Paso: 500/600, Perdida: 2.01776\n",
      "Epoca: 2/5, Paso: 600/600, Perdida: 1.99687\n",
      "Epoca: 3/5, Paso: 100/600, Perdida: 1.96758\n",
      "Epoca: 3/5, Paso: 200/600, Perdida: 1.91721\n",
      "Epoca: 3/5, Paso: 300/600, Perdida: 1.84037\n",
      "Epoca: 3/5, Paso: 400/600, Perdida: 1.83713\n",
      "Epoca: 3/5, Paso: 500/600, Perdida: 1.80482\n",
      "Epoca: 3/5, Paso: 600/600, Perdida: 1.75502\n",
      "Epoca: 4/5, Paso: 100/600, Perdida: 1.72608\n",
      "Epoca: 4/5, Paso: 200/600, Perdida: 1.69696\n",
      "Epoca: 4/5, Paso: 300/600, Perdida: 1.73047\n",
      "Epoca: 4/5, Paso: 400/600, Perdida: 1.68377\n",
      "Epoca: 4/5, Paso: 500/600, Perdida: 1.56398\n",
      "Epoca: 4/5, Paso: 600/600, Perdida: 1.64487\n",
      "Epoca: 5/5, Paso: 100/600, Perdida: 1.39767\n",
      "Epoca: 5/5, Paso: 200/600, Perdida: 1.52575\n",
      "Epoca: 5/5, Paso: 300/600, Perdida: 1.48958\n",
      "Epoca: 5/5, Paso: 400/600, Perdida: 1.43929\n",
      "Epoca: 5/5, Paso: 500/600, Perdida: 1.37014\n",
      "Epoca: 5/5, Paso: 600/600, Perdida: 1.39541\n"
     ]
    }
   ],
   "source": [
    "model7 = NNh1_relu(input_size, num_classes).to(device)\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = torch.optim.SGD(model7.parameters(), lr=lr)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "  for i, (xi, yi) in enumerate(train_loader):\n",
    "    \n",
    "    xi = xi.reshape(-1, 28*28).to(device)# imagenes\n",
    "    yi = yi.to(device)# etiquetas\n",
    "    \n",
    "    # Propagacion para adelante\n",
    "    output = model7(xi)\n",
    "    loss = loss_function(output, yi)\n",
    "    # Propagcion para atras y paso de optimizacion\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if (i+1) % 100 == 0:\n",
    "      print ('Epoca: {}/{}, Paso: {}/{}, Perdida: {:.5f}'.format(epoch+1,num_epochs, i+1, len(train_loader), loss.item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probando el modelo tenemos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision del modelo en 10000 imagenes: 78.6\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "  correct = 0\n",
    "  total = 0\n",
    "  for xi, yi in test_loader:\n",
    "\n",
    "    xi = xi.reshape(-1, 28*28).to(device)\n",
    "    yi = yi.to(device)\n",
    "    \n",
    "    output = model7(xi)\n",
    "    _, predicted = torch.max(output.data, 1)\n",
    "    \n",
    "    total += yi.size(0)\n",
    "    correct += (predicted == yi).sum().item()\n",
    "    \n",
    "  print(f'Precision del modelo en {total} imagenes: {100 * correct / total}')\n",
    "des.append(100 * correct / total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizador Adam\n",
    "\n",
    "Ahora repetiremos todos los modelos usando el optimizador Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Empezemos con el modelo sigmoide con una capa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoca: 1/5, Paso: 100/600, Perdida: 0.66358\n",
      "Epoca: 1/5, Paso: 200/600, Perdida: 0.56238\n",
      "Epoca: 1/5, Paso: 300/600, Perdida: 0.27439\n",
      "Epoca: 1/5, Paso: 400/600, Perdida: 0.29400\n",
      "Epoca: 1/5, Paso: 500/600, Perdida: 0.30128\n",
      "Epoca: 1/5, Paso: 600/600, Perdida: 0.27880\n",
      "Epoca: 2/5, Paso: 100/600, Perdida: 0.25165\n",
      "Epoca: 2/5, Paso: 200/600, Perdida: 0.34994\n",
      "Epoca: 2/5, Paso: 300/600, Perdida: 0.19403\n",
      "Epoca: 2/5, Paso: 400/600, Perdida: 0.25854\n",
      "Epoca: 2/5, Paso: 500/600, Perdida: 0.30435\n",
      "Epoca: 2/5, Paso: 600/600, Perdida: 0.24591\n",
      "Epoca: 3/5, Paso: 100/600, Perdida: 0.17219\n",
      "Epoca: 3/5, Paso: 200/600, Perdida: 0.16473\n",
      "Epoca: 3/5, Paso: 300/600, Perdida: 0.13085\n",
      "Epoca: 3/5, Paso: 400/600, Perdida: 0.25156\n",
      "Epoca: 3/5, Paso: 500/600, Perdida: 0.27530\n",
      "Epoca: 3/5, Paso: 600/600, Perdida: 0.13669\n",
      "Epoca: 4/5, Paso: 100/600, Perdida: 0.19306\n",
      "Epoca: 4/5, Paso: 200/600, Perdida: 0.13618\n",
      "Epoca: 4/5, Paso: 300/600, Perdida: 0.07877\n",
      "Epoca: 4/5, Paso: 400/600, Perdida: 0.11102\n",
      "Epoca: 4/5, Paso: 500/600, Perdida: 0.09916\n",
      "Epoca: 4/5, Paso: 600/600, Perdida: 0.19344\n",
      "Epoca: 5/5, Paso: 100/600, Perdida: 0.02660\n",
      "Epoca: 5/5, Paso: 200/600, Perdida: 0.05223\n",
      "Epoca: 5/5, Paso: 300/600, Perdida: 0.08831\n",
      "Epoca: 5/5, Paso: 400/600, Perdida: 0.11772\n",
      "Epoca: 5/5, Paso: 500/600, Perdida: 0.08833\n",
      "Epoca: 5/5, Paso: 600/600, Perdida: 0.18765\n"
     ]
    }
   ],
   "source": [
    "model8 = NNh1_sigm(input_size, num_classes).to(device)\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model8.parameters(), lr=lr)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "  for i, (xi, yi) in enumerate(train_loader):\n",
    "    \n",
    "    xi = xi.reshape(-1, 28*28).to(device)# imagenes\n",
    "    yi = yi.to(device)# etiquetas\n",
    "    \n",
    "    output = model8(xi)\n",
    "    loss = loss_function(output, yi)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if (i+1) % 100 == 0:\n",
    "      print ('Epoca: {}/{}, Paso: {}/{}, Perdida: {:.5f}'.format(epoch+1,num_epochs, i+1, len(train_loader), loss.item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este caso el desempeño es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision del modelo en 10000 imagenes: 96.77\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "  correct = 0\n",
    "  total = 0\n",
    "  for xi, yi in test_loader:\n",
    "    # [COMENTARIO]\n",
    "    xi = xi.reshape(-1, 28*28).to(device)\n",
    "    yi = yi.to(device)\n",
    "    \n",
    "    # [COMENTARIO]\n",
    "    output = model8(xi)\n",
    "    _, predicted = torch.max(output.data, 1)\n",
    "    \n",
    "    total += yi.size(0)\n",
    "    correct += (predicted == yi).sum().item()\n",
    "    \n",
    "  print(f'Precision del modelo en {total} imagenes: {100 * correct / total}')\n",
    "des.append(100 * correct / total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usando el modelo sigmoide de tres capas tenemos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoca: 1/5, Paso: 100/600, Perdida: 2.13491\n",
      "Epoca: 1/5, Paso: 200/600, Perdida: 1.95828\n",
      "Epoca: 1/5, Paso: 300/600, Perdida: 1.81936\n",
      "Epoca: 1/5, Paso: 400/600, Perdida: 1.81758\n",
      "Epoca: 1/5, Paso: 500/600, Perdida: 1.77828\n",
      "Epoca: 1/5, Paso: 600/600, Perdida: 1.70155\n",
      "Epoca: 2/5, Paso: 100/600, Perdida: 1.69314\n",
      "Epoca: 2/5, Paso: 200/600, Perdida: 1.71692\n",
      "Epoca: 2/5, Paso: 300/600, Perdida: 1.69198\n",
      "Epoca: 2/5, Paso: 400/600, Perdida: 1.65289\n",
      "Epoca: 2/5, Paso: 500/600, Perdida: 1.67520\n",
      "Epoca: 2/5, Paso: 600/600, Perdida: 1.66525\n",
      "Epoca: 3/5, Paso: 100/600, Perdida: 1.63010\n",
      "Epoca: 3/5, Paso: 200/600, Perdida: 1.65130\n",
      "Epoca: 3/5, Paso: 300/600, Perdida: 1.63776\n",
      "Epoca: 3/5, Paso: 400/600, Perdida: 1.61475\n",
      "Epoca: 3/5, Paso: 500/600, Perdida: 1.59816\n",
      "Epoca: 3/5, Paso: 600/600, Perdida: 1.62798\n",
      "Epoca: 4/5, Paso: 100/600, Perdida: 1.60368\n",
      "Epoca: 4/5, Paso: 200/600, Perdida: 1.59897\n",
      "Epoca: 4/5, Paso: 300/600, Perdida: 1.59199\n",
      "Epoca: 4/5, Paso: 400/600, Perdida: 1.61636\n",
      "Epoca: 4/5, Paso: 500/600, Perdida: 1.61696\n",
      "Epoca: 4/5, Paso: 600/600, Perdida: 1.61844\n",
      "Epoca: 5/5, Paso: 100/600, Perdida: 1.60946\n",
      "Epoca: 5/5, Paso: 200/600, Perdida: 1.59652\n",
      "Epoca: 5/5, Paso: 300/600, Perdida: 1.59371\n",
      "Epoca: 5/5, Paso: 400/600, Perdida: 1.57804\n",
      "Epoca: 5/5, Paso: 500/600, Perdida: 1.60289\n",
      "Epoca: 5/5, Paso: 600/600, Perdida: 1.58106\n"
     ]
    }
   ],
   "source": [
    "model9 = NNh3_sigm(input_size, num_classes).to(device)\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = torch.optim.Adam(model9.parameters(), lr=lr)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "  for i, (xi, yi) in enumerate(train_loader):\n",
    "    \n",
    "    xi = xi.reshape(-1, 28*28).to(device)# imagenes\n",
    "    yi = yi.to(device)# etiquetas\n",
    "    \n",
    "    output = model9(xi)\n",
    "    loss = loss_function(output, yi)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if (i+1) % 100 == 0:\n",
    "      print ('Epoca: {}/{}, Paso: {}/{}, Perdida: {:.5f}'.format(epoch+1,num_epochs, i+1, len(train_loader), loss.item()))\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision del modelo en 10000 imagenes: 68.83\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "  correct = 0\n",
    "  total = 0\n",
    "  for xi, yi in test_loader:\n",
    "    # [COMENTARIO]\n",
    "    xi = xi.reshape(-1, 28*28).to(device)\n",
    "    yi = yi.to(device)\n",
    "    \n",
    "    # [COMENTARIO]\n",
    "    output = model9(xi)\n",
    "    _, predicted = torch.max(output.data, 1)\n",
    "    \n",
    "    total += yi.size(0)\n",
    "    correct += (predicted == yi).sum().item()\n",
    "    \n",
    "  print(f'Precision del modelo en {total} imagenes: {100 * correct / total}')\n",
    "des.append(100 * correct / total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora veamos el modelo sigmoide con 5 capas ocultas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoca: 1/5, Paso: 100/600, Perdida: 2.24269\n",
      "Epoca: 1/5, Paso: 200/600, Perdida: 2.06630\n",
      "Epoca: 1/5, Paso: 300/600, Perdida: 2.00658\n",
      "Epoca: 1/5, Paso: 400/600, Perdida: 1.98509\n",
      "Epoca: 1/5, Paso: 500/600, Perdida: 1.98819\n",
      "Epoca: 1/5, Paso: 600/600, Perdida: 1.98372\n",
      "Epoca: 2/5, Paso: 100/600, Perdida: 1.99126\n",
      "Epoca: 2/5, Paso: 200/600, Perdida: 1.95759\n",
      "Epoca: 2/5, Paso: 300/600, Perdida: 1.95844\n",
      "Epoca: 2/5, Paso: 400/600, Perdida: 1.93538\n",
      "Epoca: 2/5, Paso: 500/600, Perdida: 1.90593\n",
      "Epoca: 2/5, Paso: 600/600, Perdida: 1.95324\n",
      "Epoca: 3/5, Paso: 100/600, Perdida: 1.91448\n",
      "Epoca: 3/5, Paso: 200/600, Perdida: 1.87518\n",
      "Epoca: 3/5, Paso: 300/600, Perdida: 1.90167\n",
      "Epoca: 3/5, Paso: 400/600, Perdida: 1.88025\n",
      "Epoca: 3/5, Paso: 500/600, Perdida: 1.88819\n",
      "Epoca: 3/5, Paso: 600/600, Perdida: 1.87560\n",
      "Epoca: 4/5, Paso: 100/600, Perdida: 1.87594\n",
      "Epoca: 4/5, Paso: 200/600, Perdida: 1.88629\n",
      "Epoca: 4/5, Paso: 300/600, Perdida: 1.88074\n",
      "Epoca: 4/5, Paso: 400/600, Perdida: 1.86547\n",
      "Epoca: 4/5, Paso: 500/600, Perdida: 1.86521\n",
      "Epoca: 4/5, Paso: 600/600, Perdida: 1.85983\n",
      "Epoca: 5/5, Paso: 100/600, Perdida: 1.90842\n",
      "Epoca: 5/5, Paso: 200/600, Perdida: 1.88996\n",
      "Epoca: 5/5, Paso: 300/600, Perdida: 1.87397\n",
      "Epoca: 5/5, Paso: 400/600, Perdida: 1.88995\n",
      "Epoca: 5/5, Paso: 500/600, Perdida: 1.87400\n",
      "Epoca: 5/5, Paso: 600/600, Perdida: 1.79316\n"
     ]
    }
   ],
   "source": [
    "model10 = NNh5_sigm(input_size, num_classes).to(device)\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = torch.optim.Adam(model10.parameters(), lr=lr)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "  for i, (xi, yi) in enumerate(train_loader):\n",
    "    \n",
    "    xi = xi.reshape(-1, 28*28).to(device)# imagenes\n",
    "    yi = yi.to(device)# etiquetas\n",
    "    \n",
    "    output = model10(xi)\n",
    "    loss = loss_function(output, yi)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if (i+1) % 100 == 0:\n",
    "      print ('Epoca: {}/{}, Paso: {}/{}, Perdida: {:.5f}'.format(epoch+1,num_epochs, i+1, len(train_loader), loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision del modelo en 10000 imagenes: 30.2\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "  correct = 0\n",
    "  total = 0\n",
    "    \n",
    "  for xi, yi in test_loader:\n",
    "    xi = xi.reshape(-1, 28*28).to(device)\n",
    "    yi = yi.to(device)\n",
    "    \n",
    "    output = model10(xi)\n",
    "    _, predicted = torch.max(output.data, 1)\n",
    "    \n",
    "    total += yi.size(0)\n",
    "    correct += (predicted == yi).sum().item()\n",
    "    \n",
    "  print(f'Precision del modelo en {total} imagenes: {100 * correct / total}')\n",
    "des.append(100 * correct / total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora veamos los modelos ReLU con optimizador Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoca: 1/5, Paso: 100/600, Perdida: 0.32941\n",
      "Epoca: 1/5, Paso: 200/600, Perdida: 0.26880\n",
      "Epoca: 1/5, Paso: 300/600, Perdida: 0.17250\n",
      "Epoca: 1/5, Paso: 400/600, Perdida: 0.14274\n",
      "Epoca: 1/5, Paso: 500/600, Perdida: 0.15252\n",
      "Epoca: 1/5, Paso: 600/600, Perdida: 0.18871\n",
      "Epoca: 2/5, Paso: 100/600, Perdida: 0.19011\n",
      "Epoca: 2/5, Paso: 200/600, Perdida: 0.19723\n",
      "Epoca: 2/5, Paso: 300/600, Perdida: 0.06461\n",
      "Epoca: 2/5, Paso: 400/600, Perdida: 0.07689\n",
      "Epoca: 2/5, Paso: 500/600, Perdida: 0.07893\n",
      "Epoca: 2/5, Paso: 600/600, Perdida: 0.07072\n",
      "Epoca: 3/5, Paso: 100/600, Perdida: 0.10660\n",
      "Epoca: 3/5, Paso: 200/600, Perdida: 0.03420\n",
      "Epoca: 3/5, Paso: 300/600, Perdida: 0.09573\n",
      "Epoca: 3/5, Paso: 400/600, Perdida: 0.09440\n",
      "Epoca: 3/5, Paso: 500/600, Perdida: 0.09727\n",
      "Epoca: 3/5, Paso: 600/600, Perdida: 0.08394\n",
      "Epoca: 4/5, Paso: 100/600, Perdida: 0.13162\n",
      "Epoca: 4/5, Paso: 200/600, Perdida: 0.02622\n",
      "Epoca: 4/5, Paso: 300/600, Perdida: 0.05100\n",
      "Epoca: 4/5, Paso: 400/600, Perdida: 0.14104\n",
      "Epoca: 4/5, Paso: 500/600, Perdida: 0.02357\n",
      "Epoca: 4/5, Paso: 600/600, Perdida: 0.10492\n",
      "Epoca: 5/5, Paso: 100/600, Perdida: 0.02790\n",
      "Epoca: 5/5, Paso: 200/600, Perdida: 0.01725\n",
      "Epoca: 5/5, Paso: 300/600, Perdida: 0.05353\n",
      "Epoca: 5/5, Paso: 400/600, Perdida: 0.05239\n",
      "Epoca: 5/5, Paso: 500/600, Perdida: 0.01808\n",
      "Epoca: 5/5, Paso: 600/600, Perdida: 0.01927\n"
     ]
    }
   ],
   "source": [
    "model11 = NNh1_relu(input_size, num_classes).to(device)\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = torch.optim.Adam(model11.parameters(), lr=lr)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "  for i, (xi, yi) in enumerate(train_loader):\n",
    "    \n",
    "    xi = xi.reshape(-1, 28*28).to(device)# imagenes\n",
    "    yi = yi.to(device)# etiquetas\n",
    "    \n",
    "    # Propagacion para adelante\n",
    "    output = model11(xi)\n",
    "    loss = loss_function(output, yi)\n",
    "    # Propagcion para atras y paso de optimizacion\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if (i+1) % 100 == 0:\n",
    "      print ('Epoca: {}/{}, Paso: {}/{}, Perdida: {:.5f}'.format(epoch+1,num_epochs, i+1, len(train_loader), loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision del modelo en 10000 imagenes: 97.91\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "  correct = 0\n",
    "  total = 0\n",
    "    \n",
    "  for xi, yi in test_loader:\n",
    "    xi = xi.reshape(-1, 28*28).to(device)\n",
    "    yi = yi.to(device)\n",
    "    \n",
    "    output = model11(xi)\n",
    "    _, predicted = torch.max(output.data, 1)\n",
    "    \n",
    "    total += yi.size(0)\n",
    "    correct += (predicted == yi).sum().item()\n",
    "    \n",
    "  print(f'Precision del modelo en {total} imagenes: {100 * correct / total}')\n",
    "des.append(100 * correct / total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usando el modelo ReLu con 3 capas tenemos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoca: 1/5, Paso: 100/600, Perdida: 0.26311\n",
      "Epoca: 1/5, Paso: 200/600, Perdida: 0.24223\n",
      "Epoca: 1/5, Paso: 300/600, Perdida: 0.23342\n",
      "Epoca: 1/5, Paso: 400/600, Perdida: 0.23327\n",
      "Epoca: 1/5, Paso: 500/600, Perdida: 0.28353\n",
      "Epoca: 1/5, Paso: 600/600, Perdida: 0.24568\n",
      "Epoca: 2/5, Paso: 100/600, Perdida: 0.10692\n",
      "Epoca: 2/5, Paso: 200/600, Perdida: 0.09132\n",
      "Epoca: 2/5, Paso: 300/600, Perdida: 0.03224\n",
      "Epoca: 2/5, Paso: 400/600, Perdida: 0.10465\n",
      "Epoca: 2/5, Paso: 500/600, Perdida: 0.10182\n",
      "Epoca: 2/5, Paso: 600/600, Perdida: 0.17879\n",
      "Epoca: 3/5, Paso: 100/600, Perdida: 0.06268\n",
      "Epoca: 3/5, Paso: 200/600, Perdida: 0.10687\n",
      "Epoca: 3/5, Paso: 300/600, Perdida: 0.12048\n",
      "Epoca: 3/5, Paso: 400/600, Perdida: 0.09436\n",
      "Epoca: 3/5, Paso: 500/600, Perdida: 0.07825\n",
      "Epoca: 3/5, Paso: 600/600, Perdida: 0.10292\n",
      "Epoca: 4/5, Paso: 100/600, Perdida: 0.01271\n",
      "Epoca: 4/5, Paso: 200/600, Perdida: 0.09670\n",
      "Epoca: 4/5, Paso: 300/600, Perdida: 0.04742\n",
      "Epoca: 4/5, Paso: 400/600, Perdida: 0.02390\n",
      "Epoca: 4/5, Paso: 500/600, Perdida: 0.07859\n",
      "Epoca: 4/5, Paso: 600/600, Perdida: 0.04748\n",
      "Epoca: 5/5, Paso: 100/600, Perdida: 0.02559\n",
      "Epoca: 5/5, Paso: 200/600, Perdida: 0.03118\n",
      "Epoca: 5/5, Paso: 300/600, Perdida: 0.03374\n",
      "Epoca: 5/5, Paso: 400/600, Perdida: 0.03324\n",
      "Epoca: 5/5, Paso: 500/600, Perdida: 0.05649\n",
      "Epoca: 5/5, Paso: 600/600, Perdida: 0.07386\n"
     ]
    }
   ],
   "source": [
    "model12 = NNh1_relu(input_size, num_classes).to(device)\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = torch.optim.Adam(model12.parameters(), lr=lr)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "  for i, (xi, yi) in enumerate(train_loader):\n",
    "    \n",
    "    xi = xi.reshape(-1, 28*28).to(device)# imagenes\n",
    "    yi = yi.to(device)# etiquetas\n",
    "    \n",
    "    # Propagacion para adelante\n",
    "    output = model12(xi)\n",
    "    loss = loss_function(output, yi)\n",
    "    # Propagcion para atras y paso de optimizacion\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if (i+1) % 100 == 0:\n",
    "      print ('Epoca: {}/{}, Paso: {}/{}, Perdida: {:.5f}'.format(epoch+1,num_epochs, i+1, len(train_loader), loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision del modelo en 10000 imagenes: 97.92\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "  correct = 0\n",
    "  total = 0\n",
    "    \n",
    "  for xi, yi in test_loader:\n",
    "    xi = xi.reshape(-1, 28*28).to(device)\n",
    "    yi = yi.to(device)\n",
    "    \n",
    "    output = model12(xi)\n",
    "    _, predicted = torch.max(output.data, 1)\n",
    "    \n",
    "    total += yi.size(0)\n",
    "    correct += (predicted == yi).sum().item()\n",
    "    \n",
    "  print(f'Precision del modelo en {total} imagenes: {100 * correct / total}')\n",
    "des.append(100 * correct / total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por último usamos el modelo ReLu con 5 capas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoca: 1/5, Paso: 100/600, Perdida: 0.33847\n",
      "Epoca: 1/5, Paso: 200/600, Perdida: 0.21915\n",
      "Epoca: 1/5, Paso: 300/600, Perdida: 0.31216\n",
      "Epoca: 1/5, Paso: 400/600, Perdida: 0.27333\n",
      "Epoca: 1/5, Paso: 500/600, Perdida: 0.10368\n",
      "Epoca: 1/5, Paso: 600/600, Perdida: 0.11107\n",
      "Epoca: 2/5, Paso: 100/600, Perdida: 0.11670\n",
      "Epoca: 2/5, Paso: 200/600, Perdida: 0.14809\n",
      "Epoca: 2/5, Paso: 300/600, Perdida: 0.18348\n",
      "Epoca: 2/5, Paso: 400/600, Perdida: 0.07196\n",
      "Epoca: 2/5, Paso: 500/600, Perdida: 0.09731\n",
      "Epoca: 2/5, Paso: 600/600, Perdida: 0.15184\n",
      "Epoca: 3/5, Paso: 100/600, Perdida: 0.10314\n",
      "Epoca: 3/5, Paso: 200/600, Perdida: 0.05126\n",
      "Epoca: 3/5, Paso: 300/600, Perdida: 0.05320\n",
      "Epoca: 3/5, Paso: 400/600, Perdida: 0.07367\n",
      "Epoca: 3/5, Paso: 500/600, Perdida: 0.02753\n",
      "Epoca: 3/5, Paso: 600/600, Perdida: 0.04321\n",
      "Epoca: 4/5, Paso: 100/600, Perdida: 0.03991\n",
      "Epoca: 4/5, Paso: 200/600, Perdida: 0.05772\n",
      "Epoca: 4/5, Paso: 300/600, Perdida: 0.02665\n",
      "Epoca: 4/5, Paso: 400/600, Perdida: 0.05149\n",
      "Epoca: 4/5, Paso: 500/600, Perdida: 0.04226\n",
      "Epoca: 4/5, Paso: 600/600, Perdida: 0.11400\n",
      "Epoca: 5/5, Paso: 100/600, Perdida: 0.07390\n",
      "Epoca: 5/5, Paso: 200/600, Perdida: 0.01518\n",
      "Epoca: 5/5, Paso: 300/600, Perdida: 0.00623\n",
      "Epoca: 5/5, Paso: 400/600, Perdida: 0.03286\n",
      "Epoca: 5/5, Paso: 500/600, Perdida: 0.02798\n",
      "Epoca: 5/5, Paso: 600/600, Perdida: 0.03166\n"
     ]
    }
   ],
   "source": [
    "model13 = NNh1_relu(input_size, num_classes).to(device)\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = torch.optim.Adam(model13.parameters(), lr=lr)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "  for i, (xi, yi) in enumerate(train_loader):\n",
    "    \n",
    "    xi = xi.reshape(-1, 28*28).to(device)# imagenes\n",
    "    yi = yi.to(device)# etiquetas\n",
    "    \n",
    "    # Propagacion para adelante\n",
    "    output = model13(xi)\n",
    "    loss = loss_function(output, yi)\n",
    "    # Propagcion para atras y paso de optimizacion\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if (i+1) % 100 == 0:\n",
    "      print ('Epoca: {}/{}, Paso: {}/{}, Perdida: {:.5f}'.format(epoch+1,num_epochs, i+1, len(train_loader), loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision del modelo en 10000 imagenes: 97.93\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "  correct = 0\n",
    "  total = 0\n",
    "    \n",
    "  for xi, yi in test_loader:\n",
    "    xi = xi.reshape(-1, 28*28).to(device)\n",
    "    yi = yi.to(device)\n",
    "    \n",
    "    output = model13(xi)\n",
    "    _, predicted = torch.max(output.data, 1)\n",
    "    \n",
    "    total += yi.size(0)\n",
    "    correct += (predicted == yi).sum().item()\n",
    "    \n",
    "  print(f'Precision del modelo en {total} imagenes: {100 * correct / total}')\n",
    "des.append(100 * correct / total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[82.99, 47.85, 10.32, 9.8, 78.87, 77.61, 78.6, 96.77, 68.83, 30.2, 97.91, 97.92, 97.93]\n"
     ]
    }
   ],
   "source": [
    "print(des)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 2160x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.bar(['RegMult','RN_sig','RN3_sig','RN5_sig','RN_rl','RN3_rl','RN5_rl','RN_s_adam','RN3_s_adam','RN5_s_adam','RN_r_adam','RN3_r_adam','RN5_r_adam'],des)\n",
    "plt.ylabel('Precisión del modelo')\n",
    "plt.rcParams[\"figure.figsize\"] = (25,5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. ¿Qué puede concluir a partir de estos experimentos? (e.g. \"SGD es mejor que Adam\", \"La red predice mejor\n",
    "cuando usamos nn.ReLU que cuando usamos nn.Sigmoid\", etc)\n",
    "\n",
    "En general Adam se comporta mejor,  particularmente para los modelos RELU. Siendo el mejor modelo el ReLu de 5 capas con optimizador Adam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
